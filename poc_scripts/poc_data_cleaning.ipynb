{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dac2ead0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import os\n",
    "import subprocess\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import logging\n",
    "from typing import Literal\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import json\n",
    "from shapely.geometry import mapping\n",
    "from shapely.validation import explain_validity, make_valid\n",
    "import fiona\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "\n",
    "# Import utility constants and functions\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0ce1236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize global constants here\n",
    "POC_FINALIZED_COUNTIES = [\n",
    "    # urban\n",
    "    '17031',\n",
    "    '13121',\n",
    "    '53033',\n",
    "    # sub-urban\n",
    "    '48491',\n",
    "    '29181',\n",
    "    '42011',\n",
    "    # rural \n",
    "    '55107',\n",
    "    '35051',\n",
    "    '17127',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9c9d0c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "#POC_DATASET = 'encumbered_parcels'\n",
    "#POC_TABLE = 'parcels'\n",
    "geo_crs = \"EPSG:4326\"\n",
    "projected_crs = \"EPSG:3857\" \n",
    "ENCUMBRANCES = [\n",
    "    'roadways',\n",
    "    'railways',\n",
    "    'protected_lands',\n",
    "    'wetlands',\n",
    "    'transmission_lines',\n",
    "    ]\n",
    "EncumbranceType = Literal[\n",
    "    'roadways',\n",
    "    'railways',\n",
    "    'protected_lands',\n",
    "    'wetlands',\n",
    "    'transmission_lines',\n",
    "]\n",
    "\n",
    "LOCAL_DATA_FOLDER = r\"C:\\Users\\eprashar\\OneDrive - CoreLogic Solutions, LLC\\github\\jan_25_proj_infra_parcels\\data\"\n",
    "COUNTY_DATA = r\"counties\\tl_2024_us_county\\tl_2024_us_county.shp\"\n",
    "RAILWAYS_DATA = r\"NTAD_North_American_Rail_Network_Lines\\NARN.gdb\" \n",
    "TRANSMISSION_LINES_DATA = r\"transmission_lines\\Transmission_Lines.shp\"\n",
    "ROADWAYS_DATA = r\"NTAD_North_American_Roads\\North_American_Roads.shp\"\n",
    "PROTECTED_LANDS = r\"C:\\Users\\eprashar\\OneDrive - CoreLogic Solutions, LLC\\github\\jan_25_proj_infra_parcels\\data\\Protected Lands\"\n",
    "WETLANDS = r\"C:\\Users\\eprashar\\OneDrive - CoreLogic Solutions, LLC\\github\\jan_25_proj_infra_parcels\\data\\Wetlands\"\n",
    "WETLAND_ATTRIBUTES = r\"Wetlands\\NWI-Code-Definitions\\NWI-Code-Definitions\\NWI_Code_Definitions.gdb\"\n",
    "PARQUET_INGESTION_PATH = r\"C:\\Users\\eprashar\\OneDrive - CoreLogic Solutions, LLC\\github\\jan_25_proj_infra_parcels\\data\\ingestion_parquets\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb6a568",
   "metadata": {},
   "source": [
    "#### 1.1 Cleaning and saving source encumbrance data in parquet format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fae1d50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make valid geometries\n",
    "def validate_and_fix_geometries(\n",
    "        gdf,\n",
    "        dataset,\n",
    "        state=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Initialize summary stats for logging\n",
    "    fixed_make_valid = 0\n",
    "    fixed_buffer_count = 0\n",
    "    dropped_count = 0\n",
    "\n",
    "    # Ensure CRS is 4326 (WGS84)\n",
    "    if gdf.crs is None:\n",
    "        print(f\"CRS is undefined; assigning EPSG:4326 directly.\")\n",
    "        gdf.set_crs(geo_crs, inplace=True)\n",
    "    elif gdf.crs != geo_crs:\n",
    "        print(f\"CRS is {gdf.crs}, transforming to {geo_crs}\")\n",
    "        gdf = gdf.to_crs(geo_crs)\n",
    "\n",
    "    # Assigning crs to a variable to save in the log file\n",
    "    original_crs = gdf.crs.to_string()\n",
    "    \n",
    "    # Loop over rows\n",
    "    for idx, row in gdf.iterrows():\n",
    "        geom = row['geometry']\n",
    "        if not geom.is_valid:\n",
    "            print(f\"Invalid geometry at index {idx}: {explain_validity(geom)}\")\n",
    "            try:\n",
    "                # Attempt to fix with make_valid\n",
    "                fixed = make_valid(geom)\n",
    "                if fixed.is_valid and not fixed.is_empty:\n",
    "                    gdf.at[idx, 'geometry'] = fixed\n",
    "                    fixed_make_valid += 1\n",
    "                else:\n",
    "                    print(f\"make_valid failed to fix geometry at index {idx}, falling back to buffer(0)\")\n",
    "                    fixed_w_buffer = geom.buffer(0)\n",
    "                    if fixed_w_buffer.is_valid and not fixed_w_buffer.is_empty:\n",
    "                        gdf.at[idx, 'geometry'] = fixed_w_buffer\n",
    "                        fixed_buffer_count += 1\n",
    "                    else:\n",
    "                        print(f\"Geometry at index {idx} is still invalid or empty after fixing. Dropping.\")\n",
    "                        gdf.at[idx, 'geometry'] = None\n",
    "            except Exception as e:\n",
    "                print(f\"Exception while fixing geometry at index {idx}: {e}. Dropping.\")\n",
    "                gdf.at[idx, 'geometry'] = None\n",
    "        else:\n",
    "            gdf.at[idx, 'geometry'] = geom\n",
    "    \n",
    "    # Drop invalid geometries\n",
    "    initial_len = len(gdf)\n",
    "    gdf = gdf[gdf['geometry'].notnull()]\n",
    "    dropped_count = initial_len - len(gdf) # gdf with dropped geometries\n",
    "\n",
    "    # Convert all remaining geometries to GeoJSON strings\n",
    "    gdf['geometry_geojson'] = gdf['geometry'].apply(lambda g: json.dumps(mapping(g)) if g is not None else None)\n",
    "    gdf = gdf.drop(columns='geometry')\n",
    "    gdf = gdf.rename(columns={'geometry_geojson': 'geometry'})\n",
    "    print(f\"Converted geometries to GeoJSON strings.\")\n",
    "    \n",
    "    # Log summary\n",
    "    os.makedirs('logs', exist_ok=True)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\").replace('.', '_')\n",
    "    log_filename = os.path.join('logs', f\"{state or 'no_state'}_{dataset}_geo_clean_log_{timestamp}.txt\")\n",
    "    print(f'Writing to log file {log_filename}...')\n",
    "\n",
    "    with open(log_filename, \"w\") as log_file:\n",
    "        log_file.write(f\"Dataset: {dataset}\\n\")\n",
    "        log_file.write(f\"State: {state}\\n\")\n",
    "        log_file.write(f\"Timestamp: {timestamp}\\n\")\n",
    "        log_file.write(f\"Original CRS: {original_crs}\\n\")\n",
    "        log_file.write(f\"Initial length of dataframe: {initial_len}\\n\")\n",
    "        log_file.write(f\"Geometries fixed using make_valid: {fixed_make_valid}\\n\")\n",
    "        log_file.write(f\"Geometries fixed using buffer(0): {fixed_buffer_count}\\n\")\n",
    "        log_file.write(f\"Geometries dropped after failed fix: {dropped_count}\\n\")\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d7771297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add wetland attributes\n",
    "def add_wetland_attributes(gdf_wetland):\n",
    "    \"\"\"\n",
    "    Load wetland attributes from a geodatabase and return as a GeoDataFrame.\n",
    "    \"\"\"\n",
    "    # Read the geodatabase\n",
    "    gdf_wetland_attributes = gpd.read_file(os.path.join(LOCAL_DATA_FOLDER, WETLAND_ATTRIBUTES))\n",
    "    \n",
    "    # Drop unnecessary columns\n",
    "    columns_to_drop = [\n",
    "        'SYSTEM', 'SYSTEM_NAME', 'SYSTEM_DEFINITION',\n",
    "        'SUBSYSTEM', 'SUBSYSTEM_DEFINITION',\n",
    "        'CLASS', 'CLASS_DEFINITION',\n",
    "        'SUBCLASS', 'SUBCLASS_DEFINITION',\n",
    "        'SPLIT_CLASS', 'SPLIT_CLASS_DEFINITION',\n",
    "        'SPLIT_SUBCLASS', 'SPLIT_SUBCLASS_NAME', 'SPLIT_SUBCLASS_DEFINITION',\n",
    "        'WATER_REGIME', 'WATER_REGIME_DEFINITION',\n",
    "        'MODIFIER1', 'MODIFIER1_NAME', 'MODIFIER1_GROUP', 'MODIFIER1_SUBGROUP', 'MODIFIER1_DEFINITION',\n",
    "        'MODIFIER2', 'MODIFIER2_NAME', 'MODIFIER2_GROUP', 'MODIFIER2_SUBGROUP', 'MODIFIER2_DEFINITION',\n",
    "        'geometry'\n",
    "    ]\n",
    "    gdf_wetland_attributes = gdf_wetland_attributes.drop(\n",
    "        columns=[col for col in columns_to_drop if col in gdf_wetland_attributes.columns])\n",
    "\n",
    "    # Join datasets using the 'ATTRIBUTE' column\n",
    "    wetlands_with_attributes = gdf_wetland.merge(\n",
    "        gdf_wetland_attributes,\n",
    "        how='left',\n",
    "        on='ATTRIBUTE'\n",
    "    )\n",
    "\n",
    "    return wetlands_with_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "093531ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define global config variable to store dataset configurations\n",
    "# Config includes paths, read arguments, and cleanup functions for each dataset\n",
    "DATASET_CONFIG = {\n",
    "    'transmission_lines': {\n",
    "        'path': TRANSMISSION_LINES_DATA,\n",
    "        'read_kwargs': {},\n",
    "        'requires_state': False,\n",
    "        'cleanup': lambda gdf: gdf\n",
    "            .drop(columns=[\n",
    "                'OBJECTID', 'SOURCE', 'SOURCEDATE', 'VAL_METHOD', 'VOLTAGE',\n",
    "                'INFERRED', 'SUB_1', 'SUB_2'\n",
    "            ])\n",
    "            .assign(Shape__Len=gdf['Shape__Len'].round(2))\n",
    "    },\n",
    "    'railways': {\n",
    "        'path': RAILWAYS_DATA,\n",
    "        'read_kwargs': {'layer': 'North_American_Rail_Network_Lines'},\n",
    "        'requires_state': False,\n",
    "        'cleanup': lambda gdf: gdf\n",
    "            .drop(columns=[\n",
    "                'FRFRANODE', 'TOFRANODE', 'STFIPS', 'CNTYFIPS', 'STATEAB', 'COUNTRY',\n",
    "                'FRADISTRCT', 'RROWNER1', 'RROWNER2', 'RROWNER3',\n",
    "                'TRKRGHTS1', 'TRKRGHTS2', 'TRKRGHTS3', 'TRKRGHTS4', 'TRKRGHTS5',\n",
    "                'TRKRGHTS6', 'TRKRGHTS7', 'TRKRGHTS8', 'TRKRGHTS9', 'DIVISION',\n",
    "                'SUBDIV', 'BRANCH', 'YARDNAME', 'PASSNGR', 'STRACNET', 'TRACKS',\n",
    "                'NET', 'MILES', 'TIMEZONE', 'SHAPE_Length'\n",
    "            ], errors='ignore')\n",
    "            .assign(KM=gdf['KM'].round(2))\n",
    "    },\n",
    "    'roadways': {\n",
    "        'path': ROADWAYS_DATA,\n",
    "        'read_kwargs': {},\n",
    "        'requires_state': False,\n",
    "        'cleanup': lambda gdf: gdf[gdf['COUNTRY'] == 2]\n",
    "            .drop(columns=['DIR', 'LINKID', 'JURISCODE', 'ROADNUM', 'CLASS', 'NHS'], errors='ignore')\n",
    "    },\n",
    "    'wetlands': {\n",
    "        'gdb_config': lambda state: {\n",
    "            'folder': WETLANDS,\n",
    "            'subfolder': f\"{state}_geodatabase_wetlands\",\n",
    "            'gdb_name': f\"{state}_geodatabase_wetlands.gdb\"\n",
    "        },\n",
    "        'requires_state': True,\n",
    "        'cleanup':  lambda gdf: gdf.drop(columns=['NWI_ID'], errors='ignore'),\n",
    "        'postprocess': lambda gdf: add_wetland_attributes(gdf)\n",
    "    },\n",
    "    'protected_lands': {\n",
    "        'gdb_config': lambda state: {\n",
    "            'folder': PROTECTED_LANDS,\n",
    "            'subfolder': f\"PADUS4_1_State_{state}_GDB_KMZ\",\n",
    "            'gdb_name': f\"PADUS4_1_State{state}.gdb\"\n",
    "        },\n",
    "        'requires_state': True,\n",
    "        'cleanup':  lambda gdf: gdf.drop(columns=[\n",
    "                'FeatClass',\n",
    "                'Category',\n",
    "                'Own_Name',\n",
    "                'Mang_Type',\n",
    "                'Mang_Name',\n",
    "                'Des_Tp',\n",
    "                'Agg_Src',\n",
    "                'GIS_Src',\n",
    "                'Src_Date',\n",
    "                'GIS_Acres',\n",
    "                'Source_PAID',\n",
    "                'Pub_Access',\n",
    "                'Access_Src',\n",
    "                'GAP_Sts',\n",
    "                'IUCN_Cat',\n",
    "                'Date_Est',\n",
    "                'Comments',\n",
    "                'Term',\n",
    "                'Duration',\n",
    "        ], errors='ignore'),\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "16dc279a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean and save dataset\n",
    "def clean_and_save_dataset(\n",
    "    dataset='railways',\n",
    "    output_format='parquet',\n",
    "    destination_path=PARQUET_INGESTION_PATH,\n",
    "    state=None\n",
    "):\n",
    "    config = DATASET_CONFIG.get(dataset)\n",
    "    if not config:\n",
    "        raise ValueError(f\"Unsupported dataset: {dataset}\")\n",
    "\n",
    "    if config.get('requires_state') and not state:\n",
    "        raise ValueError(f\"State must be provided for {dataset}\")\n",
    "\n",
    "    # Determine path\n",
    "    if 'path' in config:\n",
    "        full_path = os.path.join(LOCAL_DATA_FOLDER, config['path'])\n",
    "        gdf = gpd.read_file(full_path, **config.get('read_kwargs', {}))\n",
    "    else:\n",
    "        # Handle GDB datasets\n",
    "        gdb_info = config['gdb_config'](state)\n",
    "        gdb_path = os.path.join(LOCAL_DATA_FOLDER, gdb_info['folder'], gdb_info['subfolder'], gdb_info['gdb_name'])\n",
    "\n",
    "        # Find largest layer\n",
    "        largest_layer = max(\n",
    "            fiona.listlayers(gdb_path),\n",
    "            key=lambda layer: len(fiona.open(gdb_path, layer=layer))\n",
    "        )\n",
    "\n",
    "        gdf = gpd.read_file(gdb_path, layer=largest_layer)\n",
    "        print(f\"Loaded {dataset} data from layer: {largest_layer} with {len(gdf)} features\")\n",
    "\n",
    "    # Optional post-processing\n",
    "    if 'cleanup' in config:\n",
    "        gdf = config['cleanup'](gdf)\n",
    "\n",
    "    if 'postprocess' in config:\n",
    "        gdf = config['postprocess'](gdf)\n",
    "        print(f\"Postprocessed {dataset} data\")\n",
    "\n",
    "    # Check that geometries are valid\n",
    "    print(f'State name is {state}')\n",
    "    gdf = validate_and_fix_geometries(\n",
    "        gdf,\n",
    "        dataset,\n",
    "        state=state)\n",
    "\n",
    "    # Save output\n",
    "    if output_format == 'parquet':\n",
    "        filename = f\"{state}_{dataset}.parquet\" if state else f\"{dataset}.parquet\"\n",
    "        filepath = os.path.join(destination_path, filename)\n",
    "        gdf.to_parquet(filepath)\n",
    "        print(f\"{filename} data cleaned and saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "160c9dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credentials file is valid.\n"
     ]
    }
   ],
   "source": [
    "# Upload local parquet file to GCS bucket\n",
    "# First, define constants\n",
    "BUCKET = 'geospatial-projects'\n",
    "BUCKET_FOLDER = 'infra_parcels'\n",
    "CREDENTIALS_PATH =  r\"C:\\Users\\eprashar\\AppData\\Roaming\\gcloud\\application_default_credentials.json\"\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = str(CREDENTIALS_PATH)\n",
    "\n",
    "# Verify credentials\n",
    "utils.check_and_authenticate(CREDENTIALS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2a7ac77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the function because over-write status: True and file existence status: True...\n",
      "Loaded wetlands data from layer: PA_Wetlands with 360734 features\n",
      "Postprocessed wetlands data\n",
      "State name is PA\n",
      "CRS is PROJCS[\"NAD_1983_Albers\",GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0],UNIT[\"Degree\",0.0174532925199433]],PROJECTION[\"Albers_Conic_Equal_Area\"],PARAMETER[\"latitude_of_center\",23],PARAMETER[\"longitude_of_center\",-96],PARAMETER[\"standard_parallel_1\",29.5],PARAMETER[\"standard_parallel_2\",45.5],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]], transforming to EPSG:4326\n",
      "Invalid geometry at index 5234: Ring Self-intersection[-74.6712353979059 40.2108027739571]\n",
      "Invalid geometry at index 5944: Ring Self-intersection[-74.7140278133726 40.2135890768447]\n",
      "Invalid geometry at index 17175: Ring Self-intersection[-74.8853798504431 40.4666369759627]\n",
      "Invalid geometry at index 19002: Ring Self-intersection[-75.4090665917067 40.4104802447858]\n",
      "Invalid geometry at index 19532: Ring Self-intersection[-75.3760218463735 40.500100481056]\n",
      "Invalid geometry at index 26093: Ring Self-intersection[-75.0686459599747 40.4762306972838]\n",
      "Invalid geometry at index 30053: Ring Self-intersection[-75.9460352040845 41.0426825618579]\n",
      "Invalid geometry at index 47673: Ring Self-intersection[-76.0118764218839 40.6250927478512]\n",
      "Invalid geometry at index 47694: Ring Self-intersection[-75.6697547070162 40.2664211334078]\n",
      "Invalid geometry at index 47712: Ring Self-intersection[-75.6789026109961 40.8323518777099]\n",
      "Invalid geometry at index 49477: Ring Self-intersection[-75.1969499458751 41.6556859625655]\n",
      "Invalid geometry at index 49617: Ring Self-intersection[-75.1442675186825 41.4080891162031]\n",
      "Invalid geometry at index 51763: Ring Self-intersection[-75.4296123311513 41.5274720798261]\n",
      "Invalid geometry at index 60798: Ring Self-intersection[-74.760728937542 41.451335890718]\n",
      "Invalid geometry at index 70489: Ring Self-intersection[-75.0496523825481 40.9557987419338]\n",
      "Invalid geometry at index 70986: Ring Self-intersection[-75.0180629601022 40.9968466187244]\n",
      "Invalid geometry at index 72703: Ring Self-intersection[-75.8876706687501 41.8688868773369]\n",
      "Invalid geometry at index 72924: Ring Self-intersection[-75.8811150084043 41.8406510182387]\n",
      "Invalid geometry at index 74455: Ring Self-intersection[-75.6317717513796 41.864263552428]\n",
      "Invalid geometry at index 84441: Ring Self-intersection[-75.6643575174316 41.6067593239425]\n",
      "Invalid geometry at index 97870: Ring Self-intersection[-76.5752627911027 41.734895932268]\n",
      "Invalid geometry at index 109083: Ring Self-intersection[-76.8181372612827 41.5915873604693]\n",
      "Invalid geometry at index 111243: Ring Self-intersection[-76.8424360065419 41.6182934151957]\n",
      "Invalid geometry at index 124805: Ring Self-intersection[-77.4938960107591 42.0814137156753]\n",
      "Invalid geometry at index 125390: Ring Self-intersection[-77.6629191341581 42.0857821543514]\n",
      "Invalid geometry at index 125430: Ring Self-intersection[-77.7367353181383 40.5000750881783]\n",
      "Invalid geometry at index 131331: Ring Self-intersection[-78.0537028456068 40.9063531653543]\n",
      "Invalid geometry at index 141403: Ring Self-intersection[-78.2155713484014 40.9254994058581]\n",
      "Invalid geometry at index 160455: Ring Self-intersection[-80.0942083252195 42.1666943953775]\n",
      "Invalid geometry at index 166884: Ring Self-intersection[-79.1549658352766 42.0191828733318]\n",
      "Invalid geometry at index 167310: Ring Self-intersection[-79.4555302318372 42.075811314507]\n",
      "Invalid geometry at index 186222: Ring Self-intersection[-79.8096851235285 42.0115887486063]\n",
      "Invalid geometry at index 188181: Ring Self-intersection[-80.2497827644696 41.8325611010171]\n",
      "Invalid geometry at index 199964: Ring Self-intersection[-80.4721669690391 41.9257979244544]\n",
      "Invalid geometry at index 200472: Ring Self-intersection[-80.443119125804 41.86540296703]\n",
      "Invalid geometry at index 200483: Ring Self-intersection[-80.1397828151848 42.1439127063726]\n",
      "Invalid geometry at index 201350: Ring Self-intersection[-80.5466873888779 41.4446332186607]\n",
      "Invalid geometry at index 201728: Ring Self-intersection[-80.5885799068153 41.6121101810184]\n",
      "Invalid geometry at index 211113: Ring Self-intersection[-80.6240172184087 41.6873801914591]\n",
      "Invalid geometry at index 211168: Ring Self-intersection[-80.4997921705018 41.7242876975626]\n",
      "Invalid geometry at index 211251: Ring Self-intersection[-74.7916229963134 40.0139286072564]\n",
      "Invalid geometry at index 222513: Ring Self-intersection[-75.1739518412582 39.7664013514192]\n",
      "Invalid geometry at index 222522: Ring Self-intersection[-75.1784042542764 39.8120266059614]\n",
      "Invalid geometry at index 222524: Ring Self-intersection[-75.2763151884036 39.8009139218373]\n",
      "Invalid geometry at index 235791: Ring Self-intersection[-77.0085553948154 39.6410867443429]\n",
      "Invalid geometry at index 242804: Ring Self-intersection[-76.6692410031084 40.0712901727497]\n",
      "Invalid geometry at index 256181: Ring Self-intersection[-78.3364323475786 40.8327565671504]\n",
      "Invalid geometry at index 277142: Ring Self-intersection[-77.0346581519444 39.930499274331]\n",
      "Invalid geometry at index 278590: Ring Self-intersection[-77.487177540393 39.7150586903161]\n",
      "Invalid geometry at index 339590: Ring Self-intersection[-80.3747862804763 40.9666850255253]\n",
      "Invalid geometry at index 344382: Ring Self-intersection[-80.1247801678513 39.9415721176107]\n",
      "Invalid geometry at index 356361: Ring Self-intersection[-80.5900538097434 40.9629520157292]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 22\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# Attempt to run the function\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# Print the reason for running the function\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunning the function because over-write status: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOVERWRITE_EXISTING\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and file existence status: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(destination_file)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m---> 22\u001b[0m     clean_and_save_dataset(\n\u001b[0;32m     23\u001b[0m         dataset\u001b[38;5;241m=\u001b[39mdataset,\n\u001b[0;32m     24\u001b[0m         output_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparquet\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     25\u001b[0m         destination_path\u001b[38;5;241m=\u001b[39mPARQUET_INGESTION_PATH,\n\u001b[0;32m     26\u001b[0m         state\u001b[38;5;241m=\u001b[39mstate\n\u001b[0;32m     27\u001b[0m     )\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m processed and saved.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# Log the error and continue\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[67], line 43\u001b[0m, in \u001b[0;36mclean_and_save_dataset\u001b[1;34m(dataset, output_format, destination_path, state)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Check that geometries are valid\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mState name is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 43\u001b[0m gdf \u001b[38;5;241m=\u001b[39m validate_and_fix_geometries(\n\u001b[0;32m     44\u001b[0m     gdf,\n\u001b[0;32m     45\u001b[0m     dataset,\n\u001b[0;32m     46\u001b[0m     state\u001b[38;5;241m=\u001b[39mstate)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Save output\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparquet\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "Cell \u001b[1;32mIn[71], line 57\u001b[0m, in \u001b[0;36mvalidate_and_fix_geometries\u001b[1;34m(gdf, dataset, state)\u001b[0m\n\u001b[0;32m     54\u001b[0m dropped_count \u001b[38;5;241m=\u001b[39m initial_len \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(gdf) \u001b[38;5;66;03m# gdf with dropped geometries\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Convert all remaining geometries to GeoJSON strings\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m gdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry_geojson\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m gdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m g: json\u001b[38;5;241m.\u001b[39mdumps(mapping(g)) \u001b[38;5;28;01mif\u001b[39;00m g \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     58\u001b[0m gdf \u001b[38;5;241m=\u001b[39m gdf\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     59\u001b[0m gdf \u001b[38;5;241m=\u001b[39m gdf\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry_geojson\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "File \u001b[1;32mc:\\Users\\eprashar\\AppData\\Local\\miniforge3\\envs\\ip_dev\\Lib\\site-packages\\geopandas\\geoseries.py:680\u001b[0m, in \u001b[0;36mGeoSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m    677\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    679\u001b[0m \u001b[38;5;66;03m# to avoid warning\u001b[39;00m\n\u001b[1;32m--> 680\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mapply(func, args\u001b[38;5;241m=\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, GeoSeries):\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\eprashar\\AppData\\Local\\miniforge3\\envs\\ip_dev\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[0;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4919\u001b[0m         func,\n\u001b[0;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[0;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[0;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[1;32mc:\\Users\\eprashar\\AppData\\Local\\miniforge3\\envs\\ip_dev\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\eprashar\\AppData\\Local\\miniforge3\\envs\\ip_dev\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[0;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[0;32m   1509\u001b[0m )\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\eprashar\\AppData\\Local\\miniforge3\\envs\\ip_dev\\Lib\\site-packages\\pandas\\core\\base.py:919\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    916\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m--> 919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m    921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[1;32mc:\\Users\\eprashar\\AppData\\Local\\miniforge3\\envs\\ip_dev\\Lib\\site-packages\\pandas\\core\\arrays\\base.py:2322\u001b[0m, in \u001b[0;36mExtensionArray.map\u001b[1;34m(self, mapper, na_action)\u001b[0m\n\u001b[0;32m   2302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, mapper, na_action\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   2303\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2304\u001b[0m \u001b[38;5;124;03m    Map values using an input mapping or function.\u001b[39;00m\n\u001b[0;32m   2305\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2320\u001b[0m \u001b[38;5;124;03m        a MultiIndex will be returned.\u001b[39;00m\n\u001b[0;32m   2321\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m map_array(\u001b[38;5;28mself\u001b[39m, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n",
      "File \u001b[1;32mc:\\Users\\eprashar\\AppData\\Local\\miniforge3\\envs\\ip_dev\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[71], line 57\u001b[0m, in \u001b[0;36mvalidate_and_fix_geometries.<locals>.<lambda>\u001b[1;34m(g)\u001b[0m\n\u001b[0;32m     54\u001b[0m dropped_count \u001b[38;5;241m=\u001b[39m initial_len \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(gdf) \u001b[38;5;66;03m# gdf with dropped geometries\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Convert all remaining geometries to GeoJSON strings\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m gdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry_geojson\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m gdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m g: json\u001b[38;5;241m.\u001b[39mdumps(mapping(g)) \u001b[38;5;28;01mif\u001b[39;00m g \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     58\u001b[0m gdf \u001b[38;5;241m=\u001b[39m gdf\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     59\u001b[0m gdf \u001b[38;5;241m=\u001b[39m gdf\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry_geojson\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "File \u001b[1;32mc:\\Users\\eprashar\\AppData\\Local\\miniforge3\\envs\\ip_dev\\Lib\\site-packages\\shapely\\geometry\\geo.py:135\u001b[0m, in \u001b[0;36mmapping\u001b[1;34m(ob)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmapping\u001b[39m(ob):\n\u001b[0;32m    116\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m    Returns a GeoJSON-like mapping from a Geometry or any\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;124;03m    object which implements __geo_interface__\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;124;03m    {'type': 'Point', 'coordinates': (0.0, 0.0)}\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ob\u001b[38;5;241m.\u001b[39m__geo_interface__\n",
      "File \u001b[1;32mc:\\Users\\eprashar\\AppData\\Local\\miniforge3\\envs\\ip_dev\\Lib\\site-packages\\shapely\\geometry\\multipolygon.py:94\u001b[0m, in \u001b[0;36mMultiPolygon.__geo_interface__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__geo_interface__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     93\u001b[0m     allcoords \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m geom \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeoms:\n\u001b[0;32m     95\u001b[0m         coords \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     96\u001b[0m         coords\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mtuple\u001b[39m(geom\u001b[38;5;241m.\u001b[39mexterior\u001b[38;5;241m.\u001b[39mcoords))\n",
      "File \u001b[1;32mc:\\Users\\eprashar\\AppData\\Local\\miniforge3\\envs\\ip_dev\\Lib\\site-packages\\shapely\\geometry\\base.py:987\u001b[0m, in \u001b[0;36mGeometrySequence.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    986\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 987\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__len__\u001b[39m()):\n\u001b[0;32m    988\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_geom_item(i)\n",
      "File \u001b[1;32mc:\\Users\\eprashar\\AppData\\Local\\miniforge3\\envs\\ip_dev\\Lib\\site-packages\\shapely\\geometry\\base.py:991\u001b[0m, in \u001b[0;36mGeometrySequence.__len__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    990\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 991\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m shapely\u001b[38;5;241m.\u001b[39mget_num_geometries(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent)\n",
      "File \u001b[1;32mc:\\Users\\eprashar\\AppData\\Local\\miniforge3\\envs\\ip_dev\\Lib\\site-packages\\shapely\\decorators.py:77\u001b[0m, in \u001b[0;36mmultithreading_enabled.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m array_args:\n\u001b[0;32m     76\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arr, old_flag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(array_args, old_flags):\n",
      "File \u001b[1;32mc:\\Users\\eprashar\\AppData\\Local\\miniforge3\\envs\\ip_dev\\Lib\\site-packages\\shapely\\_geometry.py:679\u001b[0m, in \u001b[0;36mget_num_geometries\u001b[1;34m(geometry, **kwargs)\u001b[0m\n\u001b[0;32m    650\u001b[0m \u001b[38;5;129m@multithreading_enabled\u001b[39m\n\u001b[0;32m    651\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_num_geometries\u001b[39m(geometry, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    652\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns number of geometries in a collection.\u001b[39;00m\n\u001b[0;32m    653\u001b[0m \n\u001b[0;32m    654\u001b[0m \u001b[38;5;124;03m    Returns 0 for not-a-geometry values.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[38;5;124;03m    0\u001b[39;00m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 679\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mget_num_geometries(geometry, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Loop through all states and datasets to save cleaned parquet files\n",
    "# List of states and datasets\n",
    "OVERWRITE_EXISTING = True\n",
    "states = ['PA', 'GA', 'MO', 'WI', 'NM', 'IL','WA','TX']\n",
    "datasets = [ \n",
    "    #'protected_lands'\n",
    "    'wetlands']\n",
    "\n",
    "# Iterate through states and datasets\n",
    "for state in states:\n",
    "    for dataset in datasets:\n",
    "        # Construct the filename\n",
    "        filename = f\"{state}_{dataset}.parquet\" if state else f\"{dataset}.parquet\"\n",
    "        destination_file = os.path.join(PARQUET_INGESTION_PATH, filename)\n",
    "\n",
    "       # Check if the file already exists\n",
    "        if OVERWRITE_EXISTING or not os.path.exists(destination_file):\n",
    "            try:\n",
    "                # Attempt to run the function\n",
    "                # Print the reason for running the function\n",
    "                print(f'Running the function because over-write status: {OVERWRITE_EXISTING} and file existence status: {os.path.exists(destination_file)}...') \n",
    "                clean_and_save_dataset(\n",
    "                    dataset=dataset,\n",
    "                    output_format='parquet',\n",
    "                    destination_path=PARQUET_INGESTION_PATH,\n",
    "                    state=state\n",
    "                )\n",
    "                print(f\"File {filename} processed and saved.\")\n",
    "            except Exception as e:\n",
    "                # Log the error and continue\n",
    "                print(f\"Failed to process {filename}: {e}\")\n",
    "        else:\n",
    "            print(f\"File {filename} already exists. Skipping.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38a9253",
   "metadata": {},
   "source": [
    "#### 1.2 Uploading cleaned encumbrance parquets to GCS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "43c579fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to upload locally saved parquet to GCS\n",
    "def upload_parquet_to_gcs(\n",
    "        bucket_name,\n",
    "        bucket_folder,\n",
    "        dataset,\n",
    "        local_ingestion_path = PARQUET_INGESTION_PATH,\n",
    "        state=None):\n",
    "    \"\"\"\n",
    "    Uploads a local Parquet file to a GCS bucket using config structure.\n",
    "\n",
    "    Args:\n",
    "        bucket_name (str): Target GCS bucket.\n",
    "        dataset (str): One of the encumbrances in EncumbranceType\n",
    "        local_file_path (str): Local parquet file path.\n",
    "        state (str, optional): State name for datasets that include it.\n",
    "    \"\"\"\n",
    "    gcs_folder = f'{bucket_folder}/{dataset}'\n",
    "    filename = f\"{state}_{dataset}.parquet\" if state else f\"{dataset}.parquet\"\n",
    "    local_file_path = os.path.join(local_ingestion_path, filename)\n",
    "    if not os.path.exists(local_file_path):\n",
    "        raise FileNotFoundError(f\"File {local_file_path} does not exist.\")\n",
    "    destination_blob_path = f\"{gcs_folder}/{filename}\"\n",
    "\n",
    "    # GCS client upload\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_path)\n",
    "    blob.upload_from_filename(local_file_path)\n",
    "\n",
    "    print(f\"Uploaded {filename} to gs://{bucket_name}/{destination_blob_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e0e11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded PA_protected_lands.parquet to gs://geospatial-projects/infra_parcels/protected_lands/PA_protected_lands.parquet\n",
      "Uploaded GA_protected_lands.parquet to gs://geospatial-projects/infra_parcels/protected_lands/GA_protected_lands.parquet\n",
      "Uploaded MO_protected_lands.parquet to gs://geospatial-projects/infra_parcels/protected_lands/MO_protected_lands.parquet\n",
      "Uploaded WI_protected_lands.parquet to gs://geospatial-projects/infra_parcels/protected_lands/WI_protected_lands.parquet\n",
      "Uploaded NM_protected_lands.parquet to gs://geospatial-projects/infra_parcels/protected_lands/NM_protected_lands.parquet\n",
      "Uploaded IL_protected_lands.parquet to gs://geospatial-projects/infra_parcels/protected_lands/IL_protected_lands.parquet\n",
      "Uploaded WA_protected_lands.parquet to gs://geospatial-projects/infra_parcels/protected_lands/WA_protected_lands.parquet\n",
      "Uploaded TX_protected_lands.parquet to gs://geospatial-projects/infra_parcels/protected_lands/TX_protected_lands.parquet\n"
     ]
    }
   ],
   "source": [
    "# Loop over states and encumbrances to upload to GCS\n",
    "# List of states and datasets\n",
    "states = [\n",
    "    'PA',\n",
    "    'GA',\n",
    "    'MO',\n",
    "    'WI',\n",
    "    'NM',\n",
    "    'IL',\n",
    "    'WA', \n",
    "    'TX'\n",
    "    ]\n",
    "datasets = [\n",
    "    'wetlands',\n",
    "    #'protected_lands'\n",
    "    ] # To re-run all, replace this with ENCUMBRANCES\n",
    "\n",
    "for dataset in datasets:\n",
    "    if dataset in [\n",
    "        #'wetlands', \n",
    "        'protected_lands']:\n",
    "        for state in states:\n",
    "            try:\n",
    "                upload_parquet_to_gcs(\n",
    "                    bucket_name=BUCKET,\n",
    "                    bucket_folder=BUCKET_FOLDER, \n",
    "                    dataset=dataset, \n",
    "                    local_ingestion_path=PARQUET_INGESTION_PATH, \n",
    "                    state=state\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to upload {dataset} for {state}: {e}\")\n",
    "    else:\n",
    "        try:\n",
    "            upload_parquet_to_gcs(\n",
    "                bucket_name=BUCKET,\n",
    "                bucket_folder=BUCKET_FOLDER,\n",
    "                dataset=dataset, \n",
    "                local_ingestion_path=PARQUET_INGESTION_PATH\n",
    "                # No state needed\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to upload {dataset}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d93ef96",
   "metadata": {},
   "source": [
    "#### 2. Convert county boundaries to geographic projection and upload to BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4c9e25f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credentials file is valid.\n"
     ]
    }
   ],
   "source": [
    "# Upload local parquet file to GCS bucket\n",
    "# First, define constants\n",
    "GIS_PROJECT = 'clgx-gis-app-dev-06e3'\n",
    "POC_DATASET = 'encumbered_parcels'\n",
    "CREDENTIALS_PATH =  r\"C:\\Users\\eprashar\\AppData\\Roaming\\gcloud\\application_default_credentials.json\"\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = str(CREDENTIALS_PATH)\n",
    "\n",
    "# Verify credentials\n",
    "utils.check_and_authenticate(CREDENTIALS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc28151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload county data in GCS bucket after converting CRS to EPSG:4326\n",
    "def convert_upload_parquet_to_gcs_and_bigquery(\n",
    "    source_folder,\n",
    "    output_name,\n",
    "    bucket_name,\n",
    "    gcs_blob,\n",
    "    project_id,\n",
    "    dataset_id,\n",
    "    table_name\n",
    "):\n",
    "    \"\"\"\n",
    "    Converts a Parquet file with EPSG:4269 geometries to EPSG:4326,\n",
    "    uploads it to GCS, then loads it into BigQuery.\n",
    "\n",
    "    Args:\n",
    "    \"\"\"\n",
    "    # Load and convert CRS\n",
    "    input_path = os.path.join(LOCAL_DATA_FOLDER, source_folder)\n",
    "    gdf = gpd.read_file(input_path)\n",
    "    print(f\"Loaded {len(gdf)} features from {input_path}\")\n",
    "\n",
    "    # Convert geometries to WKT\n",
    "    \n",
    "\n",
    "    if gdf.crs is None or gdf.crs.to_epsg() != geo_crs:\n",
    "        gdf = gdf.to_crs(geo_crs)\n",
    "        print(\"CRS converted to EPSG:4326\")\n",
    "    else:\n",
    "        print(\"CRS already in EPSG:4326\")\n",
    "\n",
    "    # Save converted file locally\n",
    "    output_path = os.path.join(PARQUET_INGESTION_PATH, f'{output_name}')\n",
    "    gdf.to_parquet(output_path)\n",
    "    print(f\"Saved converted file to {output_path}\")\n",
    "\n",
    "    # Upload to GCS\n",
    "    gcs_blob_path = f'{gcs_blob}/{output_name}'\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(gcs_blob_path)\n",
    "    blob.upload_from_filename(output_path)\n",
    "    print(f\"Uploaded to GCS: gs://{bucket_name}/{gcs_blob_path}\")\n",
    "\n",
    "    # Load into BigQuery\n",
    "    client = bigquery.Client()\n",
    "    table_id = f\"{project_id}.{dataset_id}.{table_name}\"\n",
    "\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        source_format=bigquery.SourceFormat.PARQUET,\n",
    "        autodetect=True,\n",
    "        write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE\n",
    "    )\n",
    "\n",
    "    uri = f\"gs://{bucket_name}/{gcs_blob_path}\"\n",
    "    load_job = client.load_table_from_uri(uri, table_id, job_config=job_config)\n",
    "    load_job.result()  # Wait for job to complete\n",
    "\n",
    "    print(f\"Loaded data into BigQuery table: {table_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "52edac7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3235 features from C:\\Users\\eprashar\\OneDrive - CoreLogic Solutions, LLC\\github\\jan_25_proj_infra_parcels\\data\\counties\\tl_2024_us_county\\tl_2024_us_county.shp\n",
      "CRS converted to EPSG:4326\n",
      "Saved converted file to C:\\Users\\eprashar\\OneDrive - CoreLogic Solutions, LLC\\github\\jan_25_proj_infra_parcels\\data\\ingestion_parquets\\county_bounds.parquet\n",
      "Uploaded to GCS: gs://geospatial-projects/infra_parcels/county_bounds/county_bounds.parquet\n",
      "Loaded data into BigQuery table: clgx-gis-app-dev-06e3.encumbered_parcels.county_boundaries\n"
     ]
    }
   ],
   "source": [
    "# Executing the county data upload\n",
    "convert_upload_parquet_to_gcs_and_bigquery(\n",
    "    source_folder=COUNTY_DATA,\n",
    "    output_name='county_bounds.parquet',\n",
    "    bucket_name=BUCKET,\n",
    "    gcs_blob= f'{BUCKET_FOLDER}/county_bounds',\n",
    "    project_id=GIS_PROJECT,\n",
    "    dataset_id=POC_DATASET,\n",
    "    table_name=\"county_boundaries\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d93a84",
   "metadata": {},
   "source": [
    "#### 3.1 [Relevant for local development in python]: Get county-level encumbrance parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e8052db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load county boundary\n",
    "def get_county_boundary(fips_code):\n",
    "    \"\"\"\n",
    "    Load county boundary from shapefile and filter by FIPS code.\n",
    "    \"\"\"\n",
    "    # Read the shapefile\n",
    "    gdf_county = gpd.read_file(os.path.join(LOCAL_DATA_FOLDER, COUNTY_DATA))\n",
    "    \n",
    "    # Filter by FIPS code\n",
    "    gdf_county = gdf_county[gdf_county['GEOID'] == fips_code]\n",
    "    \n",
    "    # Convert to EPSG:4326\n",
    "    gdf_county = gdf_county.to_crs(geo_crs)\n",
    "    \n",
    "    return gdf_county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "938b2e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter encumbrance data for county\n",
    "def filter_gdf_using_boundary(gdf_encumbrance, county_boundary):\n",
    "    \"\"\"\n",
    "    Load wetland attributes from a geodatabase and join them to the wetlands GeoDataFrame\n",
    "    using the 'ATTRIBUTE' field as a key.\n",
    "\n",
    "    Parameters:\n",
    "\n",
    "    Returns:\n",
    "        GeoDataFrame: \n",
    "    \"\"\"\n",
    "\n",
    "    # Convert both dataframes to the same projection system\n",
    "    gdf_encumbrance = gdf_encumbrance.to_crs(county_boundary.crs)\n",
    "\n",
    "    # Perform a spatial join\n",
    "    filtered_encumbrance = gpd.sjoin(gdf_encumbrance, county_boundary, predicate='within')\n",
    "\n",
    "    # Drop unnecessary columns from county database\n",
    "    filtered_encumbrance.drop(columns=[\n",
    "        'index_right',\n",
    "        'STATEFP',\n",
    "        'COUNTYFP',\n",
    "        'COUNTYNS',\n",
    "        'GEOID',\n",
    "        'GEOIDFQ',\n",
    "        'LSAD',\n",
    "        'CLASSFP',\n",
    "        'MTFCC',\n",
    "        'CSAFP',\n",
    "        'CBSAFP',\n",
    "        'METDIVFP',\n",
    "        'FUNCSTAT',\n",
    "        'ALAND',\n",
    "        'AWATER',\n",
    "        'INTPTLAT',\n",
    "        'INTPTLON'], inplace=True)\n",
    "\n",
    "    # Convert epsg for filtered gdf to 4326\n",
    "    filtered_encumbrance = filtered_encumbrance.set_geometry('geometry').to_crs(geo_crs)\n",
    "    print(f'CRS of the filtered dataframe is {filtered_encumbrance.crs}')\n",
    "    return filtered_encumbrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13692134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for encumbrance type\n",
    "def load_encumbrance_for_county(\n",
    "        encumbrance_type: EncumbranceType,\n",
    "        fips,\n",
    "        state=None) -> gpd.GeoDataFrame:\n",
    "    '''\n",
    "    Load encumbrance data from <source> and return as GeoDataFrame.\n",
    "    '''\n",
    "    # Flag error if chosen encumbrance is not defined\n",
    "    if encumbrance_type not in ENCUMBRANCES:\n",
    "        raise ValueError(\n",
    "            f\"Invalid encumbrance type '{encumbrance_type}'. \"\n",
    "            f\"Valid options are: {', '.join(ENCUMBRANCES)}.\"\n",
    "        )\n",
    "    # Obtain county boundary\n",
    "    county_boundary = get_county_boundary(fips)\n",
    "\n",
    "    # Read the parquet file for the encumbrance type\n",
    "    try:\n",
    "        file_path = os.path.join(PARQUET_INGESTION_PATH, f'{state}_{encumbrance_type}.parquet' if state else f'{encumbrance_type}.parquet')\n",
    "        gdf = gpd.read_parquet(file_path)\n",
    "    except Exception as e:\n",
    "        raise FileNotFoundError(f\"File {file_path} not found. Error: {e}\")\n",
    "\n",
    "    # Use spatial join to get encumbrance data for county\n",
    "    county_gdf = filter_gdf_using_boundary(gdf, county_boundary)\n",
    "\n",
    "    # save county_gdf as parquet file\n",
    "    print(f\"{encumbrance_type} data loaded for FIPS code: {fips}\")\n",
    "    \n",
    "    # Convert to EPSG:4326\n",
    "    county_gdf = county_gdf.to_crs(geo_crs)\n",
    "    county_gdf.to_parquet(os.path.join(PARQUET_INGESTION_PATH,f'{fips}_{encumbrance_type}.parquet'))\n",
    "    print(f'{encumbrance_type} parquet created for {fips}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6cd64102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 17031_roadways.parquet already exists. Skipping.\n",
      "File 17031_railways.parquet already exists. Skipping.\n",
      "File 17031_protected_lands.parquet already exists. Skipping.\n",
      "File 17031_wetlands.parquet already exists. Skipping.\n",
      "CRS of the filtered dataframe is {\"$schema\": \"https://proj.org/schemas/v0.7/projjson.schema.json\", \"type\": \"GeographicCRS\", \"name\": \"WGS 84\", \"datum_ensemble\": {\"name\": \"World Geodetic System 1984 ensemble\", \"members\": [{\"name\": \"World Geodetic System 1984 (Transit)\"}, {\"name\": \"World Geodetic System 1984 (G730)\"}, {\"name\": \"World Geodetic System 1984 (G873)\"}, {\"name\": \"World Geodetic System 1984 (G1150)\"}, {\"name\": \"World Geodetic System 1984 (G1674)\"}, {\"name\": \"World Geodetic System 1984 (G1762)\"}, {\"name\": \"World Geodetic System 1984 (G2139)\"}], \"ellipsoid\": {\"name\": \"WGS 84\", \"semi_major_axis\": 6378137, \"inverse_flattening\": 298.257223563}, \"accuracy\": \"2.0\", \"id\": {\"authority\": \"EPSG\", \"code\": 6326}}, \"coordinate_system\": {\"subtype\": \"ellipsoidal\", \"axis\": [{\"name\": \"Geodetic latitude\", \"abbreviation\": \"Lat\", \"direction\": \"north\", \"unit\": \"degree\"}, {\"name\": \"Geodetic longitude\", \"abbreviation\": \"Lon\", \"direction\": \"east\", \"unit\": \"degree\"}]}, \"scope\": \"Horizontal component of 3D system.\", \"area\": \"World.\", \"bbox\": {\"south_latitude\": -90, \"west_longitude\": -180, \"north_latitude\": 90, \"east_longitude\": 180}, \"id\": {\"authority\": \"EPSG\", \"code\": 4326}}\n",
      "transmission_lines data loaded for FIPS code: 17031\n",
      "transmission_lines parquet created for 17031!\n",
      "File 17031_transmission_lines.parquet processed and saved.\n",
      "File 13121_roadways.parquet already exists. Skipping.\n",
      "File 13121_railways.parquet already exists. Skipping.\n",
      "File 13121_protected_lands.parquet already exists. Skipping.\n",
      "File 13121_wetlands.parquet already exists. Skipping.\n",
      "CRS of the filtered dataframe is {\"$schema\": \"https://proj.org/schemas/v0.7/projjson.schema.json\", \"type\": \"GeographicCRS\", \"name\": \"WGS 84\", \"datum_ensemble\": {\"name\": \"World Geodetic System 1984 ensemble\", \"members\": [{\"name\": \"World Geodetic System 1984 (Transit)\"}, {\"name\": \"World Geodetic System 1984 (G730)\"}, {\"name\": \"World Geodetic System 1984 (G873)\"}, {\"name\": \"World Geodetic System 1984 (G1150)\"}, {\"name\": \"World Geodetic System 1984 (G1674)\"}, {\"name\": \"World Geodetic System 1984 (G1762)\"}, {\"name\": \"World Geodetic System 1984 (G2139)\"}], \"ellipsoid\": {\"name\": \"WGS 84\", \"semi_major_axis\": 6378137, \"inverse_flattening\": 298.257223563}, \"accuracy\": \"2.0\", \"id\": {\"authority\": \"EPSG\", \"code\": 6326}}, \"coordinate_system\": {\"subtype\": \"ellipsoidal\", \"axis\": [{\"name\": \"Geodetic latitude\", \"abbreviation\": \"Lat\", \"direction\": \"north\", \"unit\": \"degree\"}, {\"name\": \"Geodetic longitude\", \"abbreviation\": \"Lon\", \"direction\": \"east\", \"unit\": \"degree\"}]}, \"scope\": \"Horizontal component of 3D system.\", \"area\": \"World.\", \"bbox\": {\"south_latitude\": -90, \"west_longitude\": -180, \"north_latitude\": 90, \"east_longitude\": 180}, \"id\": {\"authority\": \"EPSG\", \"code\": 4326}}\n",
      "transmission_lines data loaded for FIPS code: 13121\n",
      "transmission_lines parquet created for 13121!\n",
      "File 13121_transmission_lines.parquet processed and saved.\n",
      "File 53033_roadways.parquet already exists. Skipping.\n",
      "File 53033_railways.parquet already exists. Skipping.\n",
      "File 53033_protected_lands.parquet already exists. Skipping.\n",
      "File 53033_wetlands.parquet already exists. Skipping.\n",
      "CRS of the filtered dataframe is {\"$schema\": \"https://proj.org/schemas/v0.7/projjson.schema.json\", \"type\": \"GeographicCRS\", \"name\": \"WGS 84\", \"datum_ensemble\": {\"name\": \"World Geodetic System 1984 ensemble\", \"members\": [{\"name\": \"World Geodetic System 1984 (Transit)\"}, {\"name\": \"World Geodetic System 1984 (G730)\"}, {\"name\": \"World Geodetic System 1984 (G873)\"}, {\"name\": \"World Geodetic System 1984 (G1150)\"}, {\"name\": \"World Geodetic System 1984 (G1674)\"}, {\"name\": \"World Geodetic System 1984 (G1762)\"}, {\"name\": \"World Geodetic System 1984 (G2139)\"}], \"ellipsoid\": {\"name\": \"WGS 84\", \"semi_major_axis\": 6378137, \"inverse_flattening\": 298.257223563}, \"accuracy\": \"2.0\", \"id\": {\"authority\": \"EPSG\", \"code\": 6326}}, \"coordinate_system\": {\"subtype\": \"ellipsoidal\", \"axis\": [{\"name\": \"Geodetic latitude\", \"abbreviation\": \"Lat\", \"direction\": \"north\", \"unit\": \"degree\"}, {\"name\": \"Geodetic longitude\", \"abbreviation\": \"Lon\", \"direction\": \"east\", \"unit\": \"degree\"}]}, \"scope\": \"Horizontal component of 3D system.\", \"area\": \"World.\", \"bbox\": {\"south_latitude\": -90, \"west_longitude\": -180, \"north_latitude\": 90, \"east_longitude\": 180}, \"id\": {\"authority\": \"EPSG\", \"code\": 4326}}\n",
      "transmission_lines data loaded for FIPS code: 53033\n",
      "transmission_lines parquet created for 53033!\n",
      "File 53033_transmission_lines.parquet processed and saved.\n",
      "File 48491_roadways.parquet already exists. Skipping.\n",
      "File 48491_railways.parquet already exists. Skipping.\n",
      "File 48491_protected_lands.parquet already exists. Skipping.\n",
      "File 48491_wetlands.parquet already exists. Skipping.\n",
      "CRS of the filtered dataframe is {\"$schema\": \"https://proj.org/schemas/v0.7/projjson.schema.json\", \"type\": \"GeographicCRS\", \"name\": \"WGS 84\", \"datum_ensemble\": {\"name\": \"World Geodetic System 1984 ensemble\", \"members\": [{\"name\": \"World Geodetic System 1984 (Transit)\"}, {\"name\": \"World Geodetic System 1984 (G730)\"}, {\"name\": \"World Geodetic System 1984 (G873)\"}, {\"name\": \"World Geodetic System 1984 (G1150)\"}, {\"name\": \"World Geodetic System 1984 (G1674)\"}, {\"name\": \"World Geodetic System 1984 (G1762)\"}, {\"name\": \"World Geodetic System 1984 (G2139)\"}], \"ellipsoid\": {\"name\": \"WGS 84\", \"semi_major_axis\": 6378137, \"inverse_flattening\": 298.257223563}, \"accuracy\": \"2.0\", \"id\": {\"authority\": \"EPSG\", \"code\": 6326}}, \"coordinate_system\": {\"subtype\": \"ellipsoidal\", \"axis\": [{\"name\": \"Geodetic latitude\", \"abbreviation\": \"Lat\", \"direction\": \"north\", \"unit\": \"degree\"}, {\"name\": \"Geodetic longitude\", \"abbreviation\": \"Lon\", \"direction\": \"east\", \"unit\": \"degree\"}]}, \"scope\": \"Horizontal component of 3D system.\", \"area\": \"World.\", \"bbox\": {\"south_latitude\": -90, \"west_longitude\": -180, \"north_latitude\": 90, \"east_longitude\": 180}, \"id\": {\"authority\": \"EPSG\", \"code\": 4326}}\n",
      "transmission_lines data loaded for FIPS code: 48491\n",
      "transmission_lines parquet created for 48491!\n",
      "File 48491_transmission_lines.parquet processed and saved.\n",
      "File 29181_roadways.parquet already exists. Skipping.\n",
      "File 29181_railways.parquet already exists. Skipping.\n",
      "File 29181_protected_lands.parquet already exists. Skipping.\n",
      "File 29181_wetlands.parquet already exists. Skipping.\n",
      "CRS of the filtered dataframe is {\"$schema\": \"https://proj.org/schemas/v0.7/projjson.schema.json\", \"type\": \"GeographicCRS\", \"name\": \"WGS 84\", \"datum_ensemble\": {\"name\": \"World Geodetic System 1984 ensemble\", \"members\": [{\"name\": \"World Geodetic System 1984 (Transit)\"}, {\"name\": \"World Geodetic System 1984 (G730)\"}, {\"name\": \"World Geodetic System 1984 (G873)\"}, {\"name\": \"World Geodetic System 1984 (G1150)\"}, {\"name\": \"World Geodetic System 1984 (G1674)\"}, {\"name\": \"World Geodetic System 1984 (G1762)\"}, {\"name\": \"World Geodetic System 1984 (G2139)\"}], \"ellipsoid\": {\"name\": \"WGS 84\", \"semi_major_axis\": 6378137, \"inverse_flattening\": 298.257223563}, \"accuracy\": \"2.0\", \"id\": {\"authority\": \"EPSG\", \"code\": 6326}}, \"coordinate_system\": {\"subtype\": \"ellipsoidal\", \"axis\": [{\"name\": \"Geodetic latitude\", \"abbreviation\": \"Lat\", \"direction\": \"north\", \"unit\": \"degree\"}, {\"name\": \"Geodetic longitude\", \"abbreviation\": \"Lon\", \"direction\": \"east\", \"unit\": \"degree\"}]}, \"scope\": \"Horizontal component of 3D system.\", \"area\": \"World.\", \"bbox\": {\"south_latitude\": -90, \"west_longitude\": -180, \"north_latitude\": 90, \"east_longitude\": 180}, \"id\": {\"authority\": \"EPSG\", \"code\": 4326}}\n",
      "transmission_lines data loaded for FIPS code: 29181\n",
      "transmission_lines parquet created for 29181!\n",
      "File 29181_transmission_lines.parquet processed and saved.\n",
      "File 42011_roadways.parquet already exists. Skipping.\n",
      "File 42011_railways.parquet already exists. Skipping.\n",
      "File 42011_protected_lands.parquet already exists. Skipping.\n",
      "File 42011_wetlands.parquet already exists. Skipping.\n",
      "CRS of the filtered dataframe is {\"$schema\": \"https://proj.org/schemas/v0.7/projjson.schema.json\", \"type\": \"GeographicCRS\", \"name\": \"WGS 84\", \"datum_ensemble\": {\"name\": \"World Geodetic System 1984 ensemble\", \"members\": [{\"name\": \"World Geodetic System 1984 (Transit)\"}, {\"name\": \"World Geodetic System 1984 (G730)\"}, {\"name\": \"World Geodetic System 1984 (G873)\"}, {\"name\": \"World Geodetic System 1984 (G1150)\"}, {\"name\": \"World Geodetic System 1984 (G1674)\"}, {\"name\": \"World Geodetic System 1984 (G1762)\"}, {\"name\": \"World Geodetic System 1984 (G2139)\"}], \"ellipsoid\": {\"name\": \"WGS 84\", \"semi_major_axis\": 6378137, \"inverse_flattening\": 298.257223563}, \"accuracy\": \"2.0\", \"id\": {\"authority\": \"EPSG\", \"code\": 6326}}, \"coordinate_system\": {\"subtype\": \"ellipsoidal\", \"axis\": [{\"name\": \"Geodetic latitude\", \"abbreviation\": \"Lat\", \"direction\": \"north\", \"unit\": \"degree\"}, {\"name\": \"Geodetic longitude\", \"abbreviation\": \"Lon\", \"direction\": \"east\", \"unit\": \"degree\"}]}, \"scope\": \"Horizontal component of 3D system.\", \"area\": \"World.\", \"bbox\": {\"south_latitude\": -90, \"west_longitude\": -180, \"north_latitude\": 90, \"east_longitude\": 180}, \"id\": {\"authority\": \"EPSG\", \"code\": 4326}}\n",
      "transmission_lines data loaded for FIPS code: 42011\n",
      "transmission_lines parquet created for 42011!\n",
      "File 42011_transmission_lines.parquet processed and saved.\n",
      "File 55107_roadways.parquet already exists. Skipping.\n",
      "File 55107_railways.parquet already exists. Skipping.\n",
      "File 55107_protected_lands.parquet already exists. Skipping.\n",
      "CRS of the filtered dataframe is {\"$schema\": \"https://proj.org/schemas/v0.7/projjson.schema.json\", \"type\": \"GeographicCRS\", \"name\": \"WGS 84\", \"datum_ensemble\": {\"name\": \"World Geodetic System 1984 ensemble\", \"members\": [{\"name\": \"World Geodetic System 1984 (Transit)\"}, {\"name\": \"World Geodetic System 1984 (G730)\"}, {\"name\": \"World Geodetic System 1984 (G873)\"}, {\"name\": \"World Geodetic System 1984 (G1150)\"}, {\"name\": \"World Geodetic System 1984 (G1674)\"}, {\"name\": \"World Geodetic System 1984 (G1762)\"}, {\"name\": \"World Geodetic System 1984 (G2139)\"}], \"ellipsoid\": {\"name\": \"WGS 84\", \"semi_major_axis\": 6378137, \"inverse_flattening\": 298.257223563}, \"accuracy\": \"2.0\", \"id\": {\"authority\": \"EPSG\", \"code\": 6326}}, \"coordinate_system\": {\"subtype\": \"ellipsoidal\", \"axis\": [{\"name\": \"Geodetic latitude\", \"abbreviation\": \"Lat\", \"direction\": \"north\", \"unit\": \"degree\"}, {\"name\": \"Geodetic longitude\", \"abbreviation\": \"Lon\", \"direction\": \"east\", \"unit\": \"degree\"}]}, \"scope\": \"Horizontal component of 3D system.\", \"area\": \"World.\", \"bbox\": {\"south_latitude\": -90, \"west_longitude\": -180, \"north_latitude\": 90, \"east_longitude\": 180}, \"id\": {\"authority\": \"EPSG\", \"code\": 4326}}\n",
      "wetlands data loaded for FIPS code: 55107\n",
      "wetlands parquet created for 55107!\n",
      "File 55107_wetlands.parquet processed and saved.\n",
      "CRS of the filtered dataframe is {\"$schema\": \"https://proj.org/schemas/v0.7/projjson.schema.json\", \"type\": \"GeographicCRS\", \"name\": \"WGS 84\", \"datum_ensemble\": {\"name\": \"World Geodetic System 1984 ensemble\", \"members\": [{\"name\": \"World Geodetic System 1984 (Transit)\"}, {\"name\": \"World Geodetic System 1984 (G730)\"}, {\"name\": \"World Geodetic System 1984 (G873)\"}, {\"name\": \"World Geodetic System 1984 (G1150)\"}, {\"name\": \"World Geodetic System 1984 (G1674)\"}, {\"name\": \"World Geodetic System 1984 (G1762)\"}, {\"name\": \"World Geodetic System 1984 (G2139)\"}], \"ellipsoid\": {\"name\": \"WGS 84\", \"semi_major_axis\": 6378137, \"inverse_flattening\": 298.257223563}, \"accuracy\": \"2.0\", \"id\": {\"authority\": \"EPSG\", \"code\": 6326}}, \"coordinate_system\": {\"subtype\": \"ellipsoidal\", \"axis\": [{\"name\": \"Geodetic latitude\", \"abbreviation\": \"Lat\", \"direction\": \"north\", \"unit\": \"degree\"}, {\"name\": \"Geodetic longitude\", \"abbreviation\": \"Lon\", \"direction\": \"east\", \"unit\": \"degree\"}]}, \"scope\": \"Horizontal component of 3D system.\", \"area\": \"World.\", \"bbox\": {\"south_latitude\": -90, \"west_longitude\": -180, \"north_latitude\": 90, \"east_longitude\": 180}, \"id\": {\"authority\": \"EPSG\", \"code\": 4326}}\n",
      "transmission_lines data loaded for FIPS code: 55107\n",
      "transmission_lines parquet created for 55107!\n",
      "File 55107_transmission_lines.parquet processed and saved.\n",
      "CRS of the filtered dataframe is {\"$schema\": \"https://proj.org/schemas/v0.7/projjson.schema.json\", \"type\": \"GeographicCRS\", \"name\": \"WGS 84\", \"datum_ensemble\": {\"name\": \"World Geodetic System 1984 ensemble\", \"members\": [{\"name\": \"World Geodetic System 1984 (Transit)\"}, {\"name\": \"World Geodetic System 1984 (G730)\"}, {\"name\": \"World Geodetic System 1984 (G873)\"}, {\"name\": \"World Geodetic System 1984 (G1150)\"}, {\"name\": \"World Geodetic System 1984 (G1674)\"}, {\"name\": \"World Geodetic System 1984 (G1762)\"}, {\"name\": \"World Geodetic System 1984 (G2139)\"}], \"ellipsoid\": {\"name\": \"WGS 84\", \"semi_major_axis\": 6378137, \"inverse_flattening\": 298.257223563}, \"accuracy\": \"2.0\", \"id\": {\"authority\": \"EPSG\", \"code\": 6326}}, \"coordinate_system\": {\"subtype\": \"ellipsoidal\", \"axis\": [{\"name\": \"Geodetic latitude\", \"abbreviation\": \"Lat\", \"direction\": \"north\", \"unit\": \"degree\"}, {\"name\": \"Geodetic longitude\", \"abbreviation\": \"Lon\", \"direction\": \"east\", \"unit\": \"degree\"}]}, \"scope\": \"Horizontal component of 3D system.\", \"area\": \"World.\", \"bbox\": {\"south_latitude\": -90, \"west_longitude\": -180, \"north_latitude\": 90, \"east_longitude\": 180}, \"id\": {\"authority\": \"EPSG\", \"code\": 4326}}\n",
      "roadways data loaded for FIPS code: 35051\n",
      "roadways parquet created for 35051!\n",
      "File 35051_roadways.parquet processed and saved.\n",
      "CRS of the filtered dataframe is {\"$schema\": \"https://proj.org/schemas/v0.7/projjson.schema.json\", \"type\": \"GeographicCRS\", \"name\": \"WGS 84\", \"datum_ensemble\": {\"name\": \"World Geodetic System 1984 ensemble\", \"members\": [{\"name\": \"World Geodetic System 1984 (Transit)\"}, {\"name\": \"World Geodetic System 1984 (G730)\"}, {\"name\": \"World Geodetic System 1984 (G873)\"}, {\"name\": \"World Geodetic System 1984 (G1150)\"}, {\"name\": \"World Geodetic System 1984 (G1674)\"}, {\"name\": \"World Geodetic System 1984 (G1762)\"}, {\"name\": \"World Geodetic System 1984 (G2139)\"}], \"ellipsoid\": {\"name\": \"WGS 84\", \"semi_major_axis\": 6378137, \"inverse_flattening\": 298.257223563}, \"accuracy\": \"2.0\", \"id\": {\"authority\": \"EPSG\", \"code\": 6326}}, \"coordinate_system\": {\"subtype\": \"ellipsoidal\", \"axis\": [{\"name\": \"Geodetic latitude\", \"abbreviation\": \"Lat\", \"direction\": \"north\", \"unit\": \"degree\"}, {\"name\": \"Geodetic longitude\", \"abbreviation\": \"Lon\", \"direction\": \"east\", \"unit\": \"degree\"}]}, \"scope\": \"Horizontal component of 3D system.\", \"area\": \"World.\", \"bbox\": {\"south_latitude\": -90, \"west_longitude\": -180, \"north_latitude\": 90, \"east_longitude\": 180}, \"id\": {\"authority\": \"EPSG\", \"code\": 4326}}\n",
      "railways data loaded for FIPS code: 35051\n",
      "railways parquet created for 35051!\n",
      "File 35051_railways.parquet processed and saved.\n",
      "CRS of the filtered dataframe is {\"$schema\": \"https://proj.org/schemas/v0.7/projjson.schema.json\", \"type\": \"GeographicCRS\", \"name\": \"WGS 84\", \"datum_ensemble\": {\"name\": \"World Geodetic System 1984 ensemble\", \"members\": [{\"name\": \"World Geodetic System 1984 (Transit)\"}, {\"name\": \"World Geodetic System 1984 (G730)\"}, {\"name\": \"World Geodetic System 1984 (G873)\"}, {\"name\": \"World Geodetic System 1984 (G1150)\"}, {\"name\": \"World Geodetic System 1984 (G1674)\"}, {\"name\": \"World Geodetic System 1984 (G1762)\"}, {\"name\": \"World Geodetic System 1984 (G2139)\"}], \"ellipsoid\": {\"name\": \"WGS 84\", \"semi_major_axis\": 6378137, \"inverse_flattening\": 298.257223563}, \"accuracy\": \"2.0\", \"id\": {\"authority\": \"EPSG\", \"code\": 6326}}, \"coordinate_system\": {\"subtype\": \"ellipsoidal\", \"axis\": [{\"name\": \"Geodetic latitude\", \"abbreviation\": \"Lat\", \"direction\": \"north\", \"unit\": \"degree\"}, {\"name\": \"Geodetic longitude\", \"abbreviation\": \"Lon\", \"direction\": \"east\", \"unit\": \"degree\"}]}, \"scope\": \"Horizontal component of 3D system.\", \"area\": \"World.\", \"bbox\": {\"south_latitude\": -90, \"west_longitude\": -180, \"north_latitude\": 90, \"east_longitude\": 180}, \"id\": {\"authority\": \"EPSG\", \"code\": 4326}}\n",
      "protected_lands data loaded for FIPS code: 35051\n",
      "protected_lands parquet created for 35051!\n",
      "File 35051_protected_lands.parquet processed and saved.\n",
      "CRS of the filtered dataframe is {\"$schema\": \"https://proj.org/schemas/v0.7/projjson.schema.json\", \"type\": \"GeographicCRS\", \"name\": \"WGS 84\", \"datum_ensemble\": {\"name\": \"World Geodetic System 1984 ensemble\", \"members\": [{\"name\": \"World Geodetic System 1984 (Transit)\"}, {\"name\": \"World Geodetic System 1984 (G730)\"}, {\"name\": \"World Geodetic System 1984 (G873)\"}, {\"name\": \"World Geodetic System 1984 (G1150)\"}, {\"name\": \"World Geodetic System 1984 (G1674)\"}, {\"name\": \"World Geodetic System 1984 (G1762)\"}, {\"name\": \"World Geodetic System 1984 (G2139)\"}], \"ellipsoid\": {\"name\": \"WGS 84\", \"semi_major_axis\": 6378137, \"inverse_flattening\": 298.257223563}, \"accuracy\": \"2.0\", \"id\": {\"authority\": \"EPSG\", \"code\": 6326}}, \"coordinate_system\": {\"subtype\": \"ellipsoidal\", \"axis\": [{\"name\": \"Geodetic latitude\", \"abbreviation\": \"Lat\", \"direction\": \"north\", \"unit\": \"degree\"}, {\"name\": \"Geodetic longitude\", \"abbreviation\": \"Lon\", \"direction\": \"east\", \"unit\": \"degree\"}]}, \"scope\": \"Horizontal component of 3D system.\", \"area\": \"World.\", \"bbox\": {\"south_latitude\": -90, \"west_longitude\": -180, \"north_latitude\": 90, \"east_longitude\": 180}, \"id\": {\"authority\": \"EPSG\", \"code\": 4326}}\n",
      "wetlands data loaded for FIPS code: 35051\n",
      "wetlands parquet created for 35051!\n",
      "File 35051_wetlands.parquet processed and saved.\n",
      "CRS of the filtered dataframe is {\"$schema\": \"https://proj.org/schemas/v0.7/projjson.schema.json\", \"type\": \"GeographicCRS\", \"name\": \"WGS 84\", \"datum_ensemble\": {\"name\": \"World Geodetic System 1984 ensemble\", \"members\": [{\"name\": \"World Geodetic System 1984 (Transit)\"}, {\"name\": \"World Geodetic System 1984 (G730)\"}, {\"name\": \"World Geodetic System 1984 (G873)\"}, {\"name\": \"World Geodetic System 1984 (G1150)\"}, {\"name\": \"World Geodetic System 1984 (G1674)\"}, {\"name\": \"World Geodetic System 1984 (G1762)\"}, {\"name\": \"World Geodetic System 1984 (G2139)\"}], \"ellipsoid\": {\"name\": \"WGS 84\", \"semi_major_axis\": 6378137, \"inverse_flattening\": 298.257223563}, \"accuracy\": \"2.0\", \"id\": {\"authority\": \"EPSG\", \"code\": 6326}}, \"coordinate_system\": {\"subtype\": \"ellipsoidal\", \"axis\": [{\"name\": \"Geodetic latitude\", \"abbreviation\": \"Lat\", \"direction\": \"north\", \"unit\": \"degree\"}, {\"name\": \"Geodetic longitude\", \"abbreviation\": \"Lon\", \"direction\": \"east\", \"unit\": \"degree\"}]}, \"scope\": \"Horizontal component of 3D system.\", \"area\": \"World.\", \"bbox\": {\"south_latitude\": -90, \"west_longitude\": -180, \"north_latitude\": 90, \"east_longitude\": 180}, \"id\": {\"authority\": \"EPSG\", \"code\": 4326}}\n",
      "transmission_lines data loaded for FIPS code: 35051\n",
      "transmission_lines parquet created for 35051!\n",
      "File 35051_transmission_lines.parquet processed and saved.\n",
      "CRS of the filtered dataframe is {\"$schema\": \"https://proj.org/schemas/v0.7/projjson.schema.json\", \"type\": \"GeographicCRS\", \"name\": \"WGS 84\", \"datum_ensemble\": {\"name\": \"World Geodetic System 1984 ensemble\", \"members\": [{\"name\": \"World Geodetic System 1984 (Transit)\"}, {\"name\": \"World Geodetic System 1984 (G730)\"}, {\"name\": \"World Geodetic System 1984 (G873)\"}, {\"name\": \"World Geodetic System 1984 (G1150)\"}, {\"name\": \"World Geodetic System 1984 (G1674)\"}, {\"name\": \"World Geodetic System 1984 (G1762)\"}, {\"name\": \"World Geodetic System 1984 (G2139)\"}], \"ellipsoid\": {\"name\": \"WGS 84\", \"semi_major_axis\": 6378137, \"inverse_flattening\": 298.257223563}, \"accuracy\": \"2.0\", \"id\": {\"authority\": \"EPSG\", \"code\": 6326}}, \"coordinate_system\": {\"subtype\": \"ellipsoidal\", \"axis\": [{\"name\": \"Geodetic latitude\", \"abbreviation\": \"Lat\", \"direction\": \"north\", \"unit\": \"degree\"}, {\"name\": \"Geodetic longitude\", \"abbreviation\": \"Lon\", \"direction\": \"east\", \"unit\": \"degree\"}]}, \"scope\": \"Horizontal component of 3D system.\", \"area\": \"World.\", \"bbox\": {\"south_latitude\": -90, \"west_longitude\": -180, \"north_latitude\": 90, \"east_longitude\": 180}, \"id\": {\"authority\": \"EPSG\", \"code\": 4326}}\n",
      "roadways data loaded for FIPS code: 17127\n",
      "roadways parquet created for 17127!\n",
      "File 17127_roadways.parquet processed and saved.\n",
      "CRS of the filtered dataframe is {\"$schema\": \"https://proj.org/schemas/v0.7/projjson.schema.json\", \"type\": \"GeographicCRS\", \"name\": \"WGS 84\", \"datum_ensemble\": {\"name\": \"World Geodetic System 1984 ensemble\", \"members\": [{\"name\": \"World Geodetic System 1984 (Transit)\"}, {\"name\": \"World Geodetic System 1984 (G730)\"}, {\"name\": \"World Geodetic System 1984 (G873)\"}, {\"name\": \"World Geodetic System 1984 (G1150)\"}, {\"name\": \"World Geodetic System 1984 (G1674)\"}, {\"name\": \"World Geodetic System 1984 (G1762)\"}, {\"name\": \"World Geodetic System 1984 (G2139)\"}], \"ellipsoid\": {\"name\": \"WGS 84\", \"semi_major_axis\": 6378137, \"inverse_flattening\": 298.257223563}, \"accuracy\": \"2.0\", \"id\": {\"authority\": \"EPSG\", \"code\": 6326}}, \"coordinate_system\": {\"subtype\": \"ellipsoidal\", \"axis\": [{\"name\": \"Geodetic latitude\", \"abbreviation\": \"Lat\", \"direction\": \"north\", \"unit\": \"degree\"}, {\"name\": \"Geodetic longitude\", \"abbreviation\": \"Lon\", \"direction\": \"east\", \"unit\": \"degree\"}]}, \"scope\": \"Horizontal component of 3D system.\", \"area\": \"World.\", \"bbox\": {\"south_latitude\": -90, \"west_longitude\": -180, \"north_latitude\": 90, \"east_longitude\": 180}, \"id\": {\"authority\": \"EPSG\", \"code\": 4326}}\n",
      "railways data loaded for FIPS code: 17127\n",
      "railways parquet created for 17127!\n",
      "File 17127_railways.parquet processed and saved.\n",
      "CRS of the filtered dataframe is {\"$schema\": \"https://proj.org/schemas/v0.7/projjson.schema.json\", \"type\": \"GeographicCRS\", \"name\": \"WGS 84\", \"datum_ensemble\": {\"name\": \"World Geodetic System 1984 ensemble\", \"members\": [{\"name\": \"World Geodetic System 1984 (Transit)\"}, {\"name\": \"World Geodetic System 1984 (G730)\"}, {\"name\": \"World Geodetic System 1984 (G873)\"}, {\"name\": \"World Geodetic System 1984 (G1150)\"}, {\"name\": \"World Geodetic System 1984 (G1674)\"}, {\"name\": \"World Geodetic System 1984 (G1762)\"}, {\"name\": \"World Geodetic System 1984 (G2139)\"}], \"ellipsoid\": {\"name\": \"WGS 84\", \"semi_major_axis\": 6378137, \"inverse_flattening\": 298.257223563}, \"accuracy\": \"2.0\", \"id\": {\"authority\": \"EPSG\", \"code\": 6326}}, \"coordinate_system\": {\"subtype\": \"ellipsoidal\", \"axis\": [{\"name\": \"Geodetic latitude\", \"abbreviation\": \"Lat\", \"direction\": \"north\", \"unit\": \"degree\"}, {\"name\": \"Geodetic longitude\", \"abbreviation\": \"Lon\", \"direction\": \"east\", \"unit\": \"degree\"}]}, \"scope\": \"Horizontal component of 3D system.\", \"area\": \"World.\", \"bbox\": {\"south_latitude\": -90, \"west_longitude\": -180, \"north_latitude\": 90, \"east_longitude\": 180}, \"id\": {\"authority\": \"EPSG\", \"code\": 4326}}\n",
      "protected_lands data loaded for FIPS code: 17127\n",
      "protected_lands parquet created for 17127!\n",
      "File 17127_protected_lands.parquet processed and saved.\n",
      "CRS of the filtered dataframe is {\"$schema\": \"https://proj.org/schemas/v0.7/projjson.schema.json\", \"type\": \"GeographicCRS\", \"name\": \"WGS 84\", \"datum_ensemble\": {\"name\": \"World Geodetic System 1984 ensemble\", \"members\": [{\"name\": \"World Geodetic System 1984 (Transit)\"}, {\"name\": \"World Geodetic System 1984 (G730)\"}, {\"name\": \"World Geodetic System 1984 (G873)\"}, {\"name\": \"World Geodetic System 1984 (G1150)\"}, {\"name\": \"World Geodetic System 1984 (G1674)\"}, {\"name\": \"World Geodetic System 1984 (G1762)\"}, {\"name\": \"World Geodetic System 1984 (G2139)\"}], \"ellipsoid\": {\"name\": \"WGS 84\", \"semi_major_axis\": 6378137, \"inverse_flattening\": 298.257223563}, \"accuracy\": \"2.0\", \"id\": {\"authority\": \"EPSG\", \"code\": 6326}}, \"coordinate_system\": {\"subtype\": \"ellipsoidal\", \"axis\": [{\"name\": \"Geodetic latitude\", \"abbreviation\": \"Lat\", \"direction\": \"north\", \"unit\": \"degree\"}, {\"name\": \"Geodetic longitude\", \"abbreviation\": \"Lon\", \"direction\": \"east\", \"unit\": \"degree\"}]}, \"scope\": \"Horizontal component of 3D system.\", \"area\": \"World.\", \"bbox\": {\"south_latitude\": -90, \"west_longitude\": -180, \"north_latitude\": 90, \"east_longitude\": 180}, \"id\": {\"authority\": \"EPSG\", \"code\": 4326}}\n",
      "wetlands data loaded for FIPS code: 17127\n",
      "wetlands parquet created for 17127!\n",
      "File 17127_wetlands.parquet processed and saved.\n",
      "CRS of the filtered dataframe is {\"$schema\": \"https://proj.org/schemas/v0.7/projjson.schema.json\", \"type\": \"GeographicCRS\", \"name\": \"WGS 84\", \"datum_ensemble\": {\"name\": \"World Geodetic System 1984 ensemble\", \"members\": [{\"name\": \"World Geodetic System 1984 (Transit)\"}, {\"name\": \"World Geodetic System 1984 (G730)\"}, {\"name\": \"World Geodetic System 1984 (G873)\"}, {\"name\": \"World Geodetic System 1984 (G1150)\"}, {\"name\": \"World Geodetic System 1984 (G1674)\"}, {\"name\": \"World Geodetic System 1984 (G1762)\"}, {\"name\": \"World Geodetic System 1984 (G2139)\"}], \"ellipsoid\": {\"name\": \"WGS 84\", \"semi_major_axis\": 6378137, \"inverse_flattening\": 298.257223563}, \"accuracy\": \"2.0\", \"id\": {\"authority\": \"EPSG\", \"code\": 6326}}, \"coordinate_system\": {\"subtype\": \"ellipsoidal\", \"axis\": [{\"name\": \"Geodetic latitude\", \"abbreviation\": \"Lat\", \"direction\": \"north\", \"unit\": \"degree\"}, {\"name\": \"Geodetic longitude\", \"abbreviation\": \"Lon\", \"direction\": \"east\", \"unit\": \"degree\"}]}, \"scope\": \"Horizontal component of 3D system.\", \"area\": \"World.\", \"bbox\": {\"south_latitude\": -90, \"west_longitude\": -180, \"north_latitude\": 90, \"east_longitude\": 180}, \"id\": {\"authority\": \"EPSG\", \"code\": 4326}}\n",
      "transmission_lines data loaded for FIPS code: 17127\n",
      "transmission_lines parquet created for 17127!\n",
      "File 17127_transmission_lines.parquet processed and saved.\n"
     ]
    }
   ],
   "source": [
    "# Mapping of county FIPS to state abbreviations\n",
    "FIPS_TO_STATE = {\n",
    "    '17031': 'IL',  # Cook County, IL\n",
    "    '13121': 'GA',  # Fulton County, GA\n",
    "    '53033': 'WA',  # King County, WA\n",
    "    '48491': 'TX',  # Williamson County, TX\n",
    "    '29181': 'MO',  # Warren County, MO\n",
    "    '42011': 'PA',  # Berks County, PA\n",
    "    '55107': 'WI',  # Rusk County, WI\n",
    "    '35051': 'NM',  # Sierra County, NM\n",
    "    '17127': 'IL',  # Massac County, IL\n",
    "}\n",
    "\n",
    "poc_fips = POC_FINALIZED_COUNTIES\n",
    "encumbrances = ENCUMBRANCES\n",
    "\n",
    "# Encumbrances that require state information\n",
    "STATE_REQUIRED_TYPES = {'wetlands', 'protected_lands'}\n",
    "\n",
    "for fips in poc_fips:\n",
    "    for encumbrance in encumbrances:\n",
    "        filename = f\"{fips}_{encumbrance}.parquet\"\n",
    "        destination_file = os.path.join(PARQUET_INGESTION_PATH, filename)\n",
    "\n",
    "        if not os.path.exists(destination_file):\n",
    "            try:\n",
    "                state = FIPS_TO_STATE.get(fips) if encumbrance in STATE_REQUIRED_TYPES else None\n",
    "\n",
    "                load_encumbrance_for_county(\n",
    "                    encumbrance_type=encumbrance,\n",
    "                    fips=fips,\n",
    "                    state=state\n",
    "                )\n",
    "                print(f\"File {filename} processed and saved.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process {filename}: {e}\")\n",
    "        else:\n",
    "            print(f\"File {filename} already exists. Skipping.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003bbf94",
   "metadata": {},
   "source": [
    "#### 3.2 [Relevant for local development in python]: Parcel data for POC counties from BigQ in parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6d8c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credentials file is valid.\n"
     ]
    }
   ],
   "source": [
    "# Define constants here\n",
    "PROJECT = 'clgx-gis-app-dev-06e3'\n",
    "DATASET = 'property'\n",
    "POC_DATASET = 'encumbered_parcels'\n",
    "POC_TABLE = 'parcels'\n",
    "CREDENTIALS_PATH =  r\"C:\\Users\\eprashar\\AppData\\Roaming\\gcloud\\application_default_credentials.json\"\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = str(CREDENTIALS_PATH)\n",
    "\n",
    "# Credentials verification\n",
    "utils.check_and_authenticate(CREDENTIALS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "253f303f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to get parcel data for the defined county\n",
    "def fetch_and_save_county_parcels(fips_code: str) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Load parcel data from BigQuery and filter by FIPS code.\n",
    "    \"\"\"\n",
    "    # Define the SQL query to filter by FIPS code\n",
    "    # TO-DO: Create a table in BQ with processed data\n",
    "    query = f\"\"\"\n",
    "        SELECT * \n",
    "        FROM `{PROJECT}.{POC_DATASET}.{POC_TABLE}`\n",
    "        WHERE fips_code = '{fips_code}'\n",
    "    \"\"\"\n",
    "    # Read the data into a GeoDataFrame\n",
    "    gdf_parcel = utils.read_bigquery_to_gdf(project=PROJECT, dataset=POC_DATASET, table=POC_TABLE, query=query, output='gpd', geometry_col='geometry')\n",
    "    \n",
    "    # Convert to EPSG:4326\n",
    "    gdf_parcel = gdf_parcel.to_crs(geo_crs)\n",
    "    print(f'CRS of the parcel dataframe is {gdf_parcel.crs}')\n",
    "    gdf_parcel.to_parquet(os.path.join(PARQUET_INGESTION_PATH,f'{fips_code}_parcels.parquet'))\n",
    "    print(f'parcel parquet created for {fips_code}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73270b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save parcel parquets for all POC counties\n",
    "for county_fips in POC_FINALIZED_COUNTIES:\n",
    "    fetch_and_save_county_parcels(fips_code=county_fips)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ip_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
