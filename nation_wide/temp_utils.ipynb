{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98d02124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from google.cloud import storage\n",
    "import utils\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery_datatransfer\n",
    "from google.cloud import bigquery\n",
    "from google.api_core.exceptions import NotFound\n",
    "import geopandas as gpd\n",
    "import fiona\n",
    "import duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ced2703f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credentials file is older than 24 hours. Re-authenticating...\n",
      "Trying reauthentication on gcloud server using shell command...\n",
      "Login window opened...please complete authentication\n",
      "Waiting for credentials file to update...\n",
      "Authentication confirmed! Credentials file updated.\n"
     ]
    }
   ],
   "source": [
    "# Uploading to GCS\n",
    "# First, validate the authentication token\n",
    "CREDENTIALS_PATH =  r\"C:\\Users\\eprashar\\AppData\\Roaming\\gcloud\\application_default_credentials.json\"\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = str(CREDENTIALS_PATH)\n",
    "\n",
    "# Verify credentials\n",
    "utils.check_and_authenticate(CREDENTIALS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "805a0127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If not using a service account, initialize the client like this:\n",
    "SOURCE_PROJECT_ID = \"clgx-gis-app-dev-06e3\"\n",
    "SOURCE_DATASET_ID = \"encumbered_parcels\"\n",
    "\n",
    "DESTINATION_PROJECT_ID = \"clgx-gis-app-uat-a0e0\"\n",
    "DESTINATION_DATASET_ID = \"proximity_parcels\"\n",
    "client = bigquery.Client(project=DESTINATION_PROJECT_ID)\n",
    "\n",
    "# ==============================================================================\n",
    "#  HELPER FUNCTIONS\n",
    "# ==============================================================================\n",
    "\n",
    "def copy_all_tables(source_project, source_dataset, dest_project, dest_dataset):\n",
    "    \"\"\"\n",
    "    Copies all tables from a source dataset to a destination dataset,\n",
    "    skipping any materialized views.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Starting Table Copy ---\")\n",
    "    print(f\"From: {source_project}.{source_dataset}\")\n",
    "    print(f\"To:   {dest_project}.{dest_dataset}\")\n",
    "\n",
    "    source_dataset_ref = f\"{source_project}.{source_dataset}\"\n",
    "    \n",
    "    try:\n",
    "        tables = client.list_tables(source_dataset_ref)\n",
    "        print(f\"Found {len(list(client.list_tables(source_dataset_ref)))} items in source dataset.\")\n",
    "\n",
    "        for table in tables:\n",
    "            # --- FIX: Check the table type and skip materialized views ---\n",
    "            if table.table_type == \"MATERIALIZED_VIEW\":\n",
    "                print(f\"  -> Skipping table: {table.table_id} (Type: MATERIALIZED_VIEW)\")\n",
    "                continue\n",
    "\n",
    "            print(f\"  -> Copying table: {table.table_id}...\")\n",
    "            \n",
    "            source_table_ref = f\"{source_project}.{source_dataset}.{table.table_id}\"\n",
    "            dest_table_ref = f\"{dest_project}.{dest_dataset}.{table.table_id}\"\n",
    "\n",
    "            # Configure the copy job\n",
    "            job_config = bigquery.CopyJobConfig()\n",
    "            job_config.write_disposition = bigquery.WriteDisposition.WRITE_TRUNCATE\n",
    "\n",
    "            # Start the copy job\n",
    "            copy_job = client.copy_table(\n",
    "                source_table_ref,\n",
    "                dest_table_ref,\n",
    "                job_config=job_config,\n",
    "            )\n",
    "            copy_job.result()  # Wait for the job to complete\n",
    "            print(f\"     -> SUCCESS: Copied to {dest_table_ref}\")\n",
    "\n",
    "    except NotFound:\n",
    "        print(f\"ERROR: Source dataset '{source_dataset_ref}' not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during table copy: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84dc62e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Table Copy ---\n",
      "From: clgx-gis-app-dev-06e3.encumbered_parcels\n",
      "To:   clgx-gis-app-uat-a0e0.proximity_parcels\n",
      "Found 19 items in source dataset.\n",
      "  -> Copying table: all_encumbrance_scores...\n",
      "     -> SUCCESS: Copied to clgx-gis-app-uat-a0e0.proximity_parcels.all_encumbrance_scores\n",
      "  -> Copying table: county_boundaries...\n",
      "     -> SUCCESS: Copied to clgx-gis-app-uat-a0e0.proximity_parcels.county_boundaries\n",
      "  -> Skipping table: parcels_mv (Type: MATERIALIZED_VIEW)\n",
      "  -> Copying table: protected_lands_national...\n",
      "     -> SUCCESS: Copied to clgx-gis-app-uat-a0e0.proximity_parcels.protected_lands_national\n",
      "  -> Skipping table: protected_lands_national_mv (Type: MATERIALIZED_VIEW)\n",
      "  -> Copying table: proximity_intersection_protected_lands_national...\n",
      "     -> SUCCESS: Copied to clgx-gis-app-uat-a0e0.proximity_parcels.proximity_intersection_protected_lands_national\n",
      "  -> Copying table: proximity_intersection_railways...\n",
      "     -> SUCCESS: Copied to clgx-gis-app-uat-a0e0.proximity_parcels.proximity_intersection_railways\n",
      "  -> Copying table: proximity_intersection_roadways...\n",
      "     -> SUCCESS: Copied to clgx-gis-app-uat-a0e0.proximity_parcels.proximity_intersection_roadways\n",
      "  -> Copying table: proximity_intersection_transmission_lines...\n",
      "     -> SUCCESS: Copied to clgx-gis-app-uat-a0e0.proximity_parcels.proximity_intersection_transmission_lines\n",
      "  -> Copying table: proximity_intersection_wetlands...\n",
      "     -> SUCCESS: Copied to clgx-gis-app-uat-a0e0.proximity_parcels.proximity_intersection_wetlands\n",
      "  -> Copying table: railways...\n",
      "     -> SUCCESS: Copied to clgx-gis-app-uat-a0e0.proximity_parcels.railways\n",
      "  -> Skipping table: railways_mv (Type: MATERIALIZED_VIEW)\n",
      "  -> Copying table: roadways...\n",
      "     -> SUCCESS: Copied to clgx-gis-app-uat-a0e0.proximity_parcels.roadways\n",
      "  -> Skipping table: roadways_mv (Type: MATERIALIZED_VIEW)\n",
      "  -> Copying table: transmission_lines...\n",
      "     -> SUCCESS: Copied to clgx-gis-app-uat-a0e0.proximity_parcels.transmission_lines\n",
      "  -> Skipping table: transmission_lines_mv (Type: MATERIALIZED_VIEW)\n",
      "  -> Copying table: wetlands...\n",
      "     -> SUCCESS: Copied to clgx-gis-app-uat-a0e0.proximity_parcels.wetlands\n",
      "  -> Copying table: wetlands_debug...\n",
      "     -> SUCCESS: Copied to clgx-gis-app-uat-a0e0.proximity_parcels.wetlands_debug\n",
      "  -> Skipping table: wetlands_mv (Type: MATERIALIZED_VIEW)\n"
     ]
    }
   ],
   "source": [
    "# Copy all tables from the source dataset to the destination dataset\n",
    "copy_all_tables(SOURCE_PROJECT_ID, SOURCE_DATASET_ID, DESTINATION_PROJECT_ID, DESTINATION_DATASET_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e3f77923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_all_routines(source_project, source_dataset, dest_project, dest_dataset):\n",
    "    \"\"\"\n",
    "    Copies all routines (stored procedures) from a source dataset to a \n",
    "    destination dataset, replacing hardcoded project and dataset IDs in the body.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Starting Stored Procedure (Routine) Copy ---\")\n",
    "    print(f\"From: {source_project}.{source_dataset}\")\n",
    "    print(f\"To:   {dest_project}.{dest_dataset}\")\n",
    "\n",
    "    source_dataset_ref = f\"{source_project}.{source_dataset}\"\n",
    "    \n",
    "    try:\n",
    "        routines = client.list_routines(source_dataset_ref)\n",
    "        routine_ids = [routine.routine_id for routine in routines]\n",
    "        print(f\"Found {len(routine_ids)} routines to copy.\")\n",
    "\n",
    "        for routine_id in routine_ids:\n",
    "            print(f\"  -> Copying routine: {routine_id}...\")\n",
    "            \n",
    "            source_routine_ref = f\"{source_project}.{source_dataset}.{routine_id}\"\n",
    "            dest_routine_ref_str = f\"{dest_project}.{dest_dataset}.{routine_id}\"\n",
    "            \n",
    "            # Get the full definition of the source routine\n",
    "            source_routine = client.get_routine(source_routine_ref)\n",
    "            \n",
    "            # 1. Get the original SQL body of the procedure\n",
    "            updated_body = source_routine.body\n",
    "            \n",
    "            # 2. Define replacement pairs. This is more flexible.\n",
    "            replacements = [\n",
    "                # Replace the primary source project and dataset\n",
    "                (f\"{source_project}.{source_dataset}\", f\"{dest_project}.{dest_dataset}\"),\n",
    "                # Replace any other hardcoded dev projects with their UAT equivalents\n",
    "                # (\"clgx-idap-bigquery-dev-71f0\", \"clgx-idap-bigquery-uat-d3f3\")\n",
    "            ]\n",
    "\n",
    "            # 3. Perform all replacements\n",
    "            for old_string, new_string in replacements:\n",
    "                updated_body = updated_body.replace(old_string, new_string)\n",
    "\n",
    "            # 4. Use the updated body for the new routine\n",
    "            source_routine.body = updated_body\n",
    "            \n",
    "            # Use the API representation for a more robust copy\n",
    "            resource = source_routine.to_api_repr()\n",
    "\n",
    "            # Update the reference to point to the new destination\n",
    "            dest_routine_ref = bigquery.RoutineReference.from_string(dest_routine_ref_str)\n",
    "            resource['routineReference'] = dest_routine_ref.to_api_repr()\n",
    "            \n",
    "            # Create a new Routine object from the modified resource\n",
    "            dest_routine = bigquery.Routine.from_api_repr(resource)\n",
    "            \n",
    "            # Create (or replace) the routine in the destination dataset\n",
    "            client.create_routine(dest_routine, exists_ok=True)\n",
    "            print(f\"     -> SUCCESS: Recreated routine at {dest_routine_ref_str} with updated references.\")\n",
    "\n",
    "    except NotFound:\n",
    "        print(f\"ERROR: Source dataset '{source_dataset_ref}' not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during routine copy: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c676fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Stored Procedure (Routine) Copy ---\n",
      "From: clgx-gis-app-dev-06e3.encumbered_parcels\n",
      "To:   clgx-gis-app-uat-a0e0.proximity_parcels\n",
      "Found 16 routines to copy.\n",
      "  -> Copying routine: calculate_intersection_score_for_polygons...\n",
      "     -> SUCCESS: Recreated routine at clgx-gis-app-uat-a0e0.proximity_parcels.calculate_intersection_score_for_polygons with updated references.\n",
      "  -> Copying routine: calculate_intersection_score_for_polygons_batch...\n",
      "     -> SUCCESS: Recreated routine at clgx-gis-app-uat-a0e0.proximity_parcels.calculate_intersection_score_for_polygons_batch with updated references.\n",
      "  -> Copying routine: calculate_intersection_score_polygons_batch...\n",
      "     -> SUCCESS: Recreated routine at clgx-gis-app-uat-a0e0.proximity_parcels.calculate_intersection_score_polygons_batch with updated references.\n",
      "  -> Copying routine: calculate_proximity_for_polygons...\n",
      "     -> SUCCESS: Recreated routine at clgx-gis-app-uat-a0e0.proximity_parcels.calculate_proximity_for_polygons with updated references.\n",
      "  -> Copying routine: calculate_proximity_for_polygons_all_counties...\n",
      "     -> SUCCESS: Recreated routine at clgx-gis-app-uat-a0e0.proximity_parcels.calculate_proximity_for_polygons_all_counties with updated references.\n",
      "  -> Copying routine: calculate_proximity_score_batch...\n",
      "     -> SUCCESS: Recreated routine at clgx-gis-app-uat-a0e0.proximity_parcels.calculate_proximity_score_batch with updated references.\n",
      "  -> Copying routine: calculate_proximity_score_for_lines...\n",
      "     -> SUCCESS: Recreated routine at clgx-gis-app-uat-a0e0.proximity_parcels.calculate_proximity_score_for_lines with updated references.\n",
      "  -> Copying routine: calculate_proximity_score_for_lines_optimized...\n",
      "     -> SUCCESS: Recreated routine at clgx-gis-app-uat-a0e0.proximity_parcels.calculate_proximity_score_for_lines_optimized with updated references.\n",
      "  -> Copying routine: calculate_proximity_score_for_lines_optimized_v2...\n",
      "     -> SUCCESS: Recreated routine at clgx-gis-app-uat-a0e0.proximity_parcels.calculate_proximity_score_for_lines_optimized_v2 with updated references.\n",
      "  -> Copying routine: calculate_proximity_score_lines_batch...\n",
      "     -> SUCCESS: Recreated routine at clgx-gis-app-uat-a0e0.proximity_parcels.calculate_proximity_score_lines_batch with updated references.\n",
      "  -> Copying routine: calculate_proximity_score_polygons_batch...\n",
      "     -> SUCCESS: Recreated routine at clgx-gis-app-uat-a0e0.proximity_parcels.calculate_proximity_score_polygons_batch with updated references.\n",
      "  -> Copying routine: consolidate_all_scores...\n",
      "     -> SUCCESS: Recreated routine at clgx-gis-app-uat-a0e0.proximity_parcels.consolidate_all_scores with updated references.\n",
      "  -> Copying routine: create_materialized_view...\n",
      "     -> SUCCESS: Recreated routine at clgx-gis-app-uat-a0e0.proximity_parcels.create_materialized_view with updated references.\n",
      "  -> Copying routine: load_encumbrance_with_fips...\n",
      "     -> SUCCESS: Recreated routine at clgx-gis-app-uat-a0e0.proximity_parcels.load_encumbrance_with_fips with updated references.\n",
      "  -> Copying routine: run_batched_proximity_line_processing...\n",
      "     -> SUCCESS: Recreated routine at clgx-gis-app-uat-a0e0.proximity_parcels.run_batched_proximity_line_processing with updated references.\n",
      "  -> Copying routine: run_batched_proximity_polygon_processing...\n",
      "     -> SUCCESS: Recreated routine at clgx-gis-app-uat-a0e0.proximity_parcels.run_batched_proximity_polygon_processing with updated references.\n"
     ]
    }
   ],
   "source": [
    "# Copy all routines\n",
    "copy_all_routines(SOURCE_PROJECT_ID, SOURCE_DATASET_ID, DESTINATION_PROJECT_ID, DESTINATION_DATASET_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6a8346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'r' before the string is important to handle the backslashes correctly.\n",
    "target_folder = r\"C:\\Users\\eprashar\\OneDrive - CoreLogic Solutions, LLC\\github\\jan_25_proj_infra_parcels\\data\\Wetlands\"\n",
    "\n",
    "print(f\"Scanning for zip files in: {target_folder}\\n\")\n",
    "\n",
    "# Loop through all the files in the target directory\n",
    "for filename in os.listdir(target_folder):\n",
    "    # Check if the file is a zip file\n",
    "    if filename.endswith(\".zip\"):\n",
    "        # Construct the full path to the zip file\n",
    "        zip_path = os.path.join(target_folder, filename)\n",
    "        print(f\"Found zip file: {filename}\")\n",
    "\n",
    "        try:\n",
    "            # Open the zip file for reading\n",
    "            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                # Extract all the contents into the target folder\n",
    "                print(f\" -> Extracting '{filename}'...\")\n",
    "                zip_ref.extractall(target_folder)\n",
    "                print(\" -> Extraction complete.\")\n",
    "\n",
    "            # If extraction was successful, delete the original zip file\n",
    "            os.remove(zip_path)\n",
    "            print(f\" -> Successfully deleted '{filename}'.\\n\")\n",
    "\n",
    "        except zipfile.BadZipFile:\n",
    "            print(f\" -> ERROR: '{filename}' is not a valid zip file or is corrupted. Skipping.\")\n",
    "        except Exception as e:\n",
    "            print(f\" -> ERROR: An unexpected error occurred with '{filename}': {e}\")\n",
    "\n",
    "print(\"--- All zip files processed. ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ip_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
