{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24d4b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import shapely.wkb\n",
    "import geopandas as gpd\n",
    "from google.cloud import storage\n",
    "\n",
    "# --- Configuration ---\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/path/to/your/credentials.json\"\n",
    "\n",
    "SOURCE_BUCKET = \"geospatial-projects\"\n",
    "SOURCE_PREFIX = \"infra_parcels/wetlands_v2/county/\"\n",
    "DESTINATION_BUCKET = \"geospatial-projects\"\n",
    "DESTINATION_PREFIX = \"infra_parcels/wetlands_v2/county_cleaned/\"\n",
    "\n",
    "# --- Script Body ---\n",
    "storage_client = storage.Client()\n",
    "\n",
    "def clean_geometry(geom):\n",
    "    \"\"\"\n",
    "    Safely loads a WKB geometry, fixes it if invalid, and returns a GeoJSON string.\n",
    "    \"\"\"\n",
    "    if geom is None:\n",
    "        return None\n",
    "    try:\n",
    "        # Load the WKB bytes into a shapely geometry object\n",
    "        shape = shapely.wkb.loads(geom)\n",
    "        \n",
    "        # The .buffer(0) trick is a powerful way to fix many invalid geometries\n",
    "        if not shape.is_valid:\n",
    "            shape = shape.buffer(0)\n",
    "            \n",
    "        return shape.to_wkt() # Using WKT for compatibility, can also be geojson\n",
    "    except Exception:\n",
    "        # If loading fails, return None\n",
    "        return None\n",
    "\n",
    "# Get a list of all non-Alaska parquet files\n",
    "blobs = storage_client.list_blobs(SOURCE_BUCKET, prefix=SOURCE_PREFIX)\n",
    "files_to_process = [\n",
    "    blob.name\n",
    "    for blob in blobs\n",
    "    if blob.name.endswith(\".parquet\") and not blob.name.startswith(f\"{SOURCE_PREFIX}AK_\")\n",
    "]\n",
    "\n",
    "print(f\"Found {len(files_to_process)} files to clean and convert.\")\n",
    "\n",
    "for i, gcs_path in enumerate(files_to_process):\n",
    "    print(f\"\\nProcessing file {i+1} of {len(files_to_process)}: {gcs_path}\")\n",
    "    \n",
    "    try:\n",
    "        # Read the parquet file directly from GCS into a GeoPandas DataFrame\n",
    "        gdf = gpd.read_parquet(f\"gs://{SOURCE_BUCKET}/{gcs_path}\")\n",
    "\n",
    "        # Apply the cleaning function to the geometry column\n",
    "        # This assumes the raw geometry column is named 'geometry'\n",
    "        gdf['geometry_cleaned'] = gdf['geometry'].apply(clean_geometry)\n",
    "        \n",
    "        # Drop rows where geometry could not be fixed\n",
    "        gdf.dropna(subset=['geometry_cleaned'], inplace=True)\n",
    "        \n",
    "        # Drop the original geometry column\n",
    "        gdf.drop(columns=['geometry'], inplace=True)\n",
    "        gdf.rename(columns={'geometry_cleaned': 'geometry'}, inplace=True)\n",
    "\n",
    "        # Write the cleaned DataFrame to a new location in GCS\n",
    "        destination_path = gcs_path.replace(SOURCE_PREFIX, DESTINATION_PREFIX)\n",
    "        gdf.to_parquet(f\"gs://{DESTINATION_BUCKET}/{destination_path}\")\n",
    "        print(f\"  SUCCESS: Wrote cleaned file to gs://{DESTINATION_BUCKET}/{destination_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  ERROR: Failed to process {gcs_path}. Reason: {e}\")\n",
    "        with open(\"failed_conversion.log\", \"a\") as f:\n",
    "            f.write(f\"{gcs_path}\\n\")\n",
    "\n",
    "print(\"\\nConversion complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
